{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result5                  0\n",
      "dtype: int64\n",
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result5                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Arnab Karmakar/Downloads/2 month.csv\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(how='any',axis=0) \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4241 entries, 0 to 4240\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Row Labels             4241 non-null   object \n",
      " 1   Symbol                 4241 non-null   object \n",
      " 2   No of Shares Bought    4241 non-null   int64  \n",
      " 3   Value of purchase      4241 non-null   float64\n",
      " 4   No of shares sold      4241 non-null   int64  \n",
      " 5   Value of sale          4241 non-null   float64\n",
      " 6   No of shares           4241 non-null   int64  \n",
      " 7   Value                  4241 non-null   float64\n",
      " 8   Avg Price              4241 non-null   float64\n",
      " 9   Buy Date               4241 non-null   object \n",
      " 10  Sell date              4241 non-null   object \n",
      " 11  Buy price              4241 non-null   float64\n",
      " 12  Sell price             4241 non-null   float64\n",
      " 13  Nifty Index at buying  4241 non-null   float64\n",
      " 14  Nfty index at selling  4241 non-null   float64\n",
      " 15  Change in Nifty 50     4241 non-null   object \n",
      " 16  Return                 4241 non-null   float64\n",
      " 17  No of shares.1         4241 non-null   int64  \n",
      " 18  Market Cap             4241 non-null   float64\n",
      " 19  %age of Marketcap      4241 non-null   float64\n",
      " 20  Cap                    4241 non-null   object \n",
      " 21  Deviation              4241 non-null   float64\n",
      " 22  EPS                    4241 non-null   float64\n",
      " 23  ROE                    4241 non-null   float64\n",
      " 24  COA                    4241 non-null   float64\n",
      " 25  CIA                    4241 non-null   float64\n",
      " 26  CFA                    4241 non-null   float64\n",
      " 27  PBT                    4241 non-null   float64\n",
      " 28  PE                     4241 non-null   float64\n",
      " 29  Industry               4241 non-null   object \n",
      " 30  Result                 4241 non-null   object \n",
      " 31  Result5                4241 non-null   object \n",
      "dtypes: float64(19), int64(4), object(9)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'SmallCap':0,'MidCap':1,'LargeCap':2}\n",
    "data['Cap']=data['Cap'].map(c)\n",
    "i={}\n",
    "count=0\n",
    "for _ in data['Industry']:\n",
    "    if _ not in i:\n",
    "        i[_]=count\n",
    "        count+=1\n",
    "data['Industry']=data['Industry'].map(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4236    0\n",
      "4237    0\n",
      "4238    0\n",
      "4239    0\n",
      "4240    0\n",
      "Name: Cap, Length: 4241, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "        ..\n",
      "4236    56\n",
      "4237     0\n",
      "4238    69\n",
      "4239    13\n",
      "4240     7\n",
      "Name: Industry, Length: 4241, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\615108639.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Buy Date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\615108639.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\615108639.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Row Labels',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\615108639.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\615108639.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell price',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Buy Date',1,inplace=True)\n",
    "data.drop('Sell date',1,inplace=True)\n",
    "data.drop('Row Labels',1,inplace=True)\n",
    "#data.drop('Symbol',1,inplace=True)\n",
    "data.drop('Return',1,inplace=True)\n",
    "data.drop('Sell price',1,inplace=True)\n",
    "data.drop('Result5',axis=1,inplace=True)\n",
    "#data.drop('Nifty Index at buying',axis=1,inplace=True)\n",
    "#data.drop('Nfty index at selling',axis=1,inplace=True)\n",
    "data.drop('Change in Nifty 50',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code'] = pd.factorize(data['Symbol'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4241 entries, 0 to 4240\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Symbol                 4241 non-null   object \n",
      " 1   No of Shares Bought    4241 non-null   int64  \n",
      " 2   Value of purchase      4241 non-null   float64\n",
      " 3   No of shares sold      4241 non-null   int64  \n",
      " 4   Value of sale          4241 non-null   float64\n",
      " 5   No of shares           4241 non-null   int64  \n",
      " 6   Value                  4241 non-null   float64\n",
      " 7   Avg Price              4241 non-null   float64\n",
      " 8   Buy price              4241 non-null   float64\n",
      " 9   Nifty Index at buying  4241 non-null   float64\n",
      " 10  Nfty index at selling  4241 non-null   float64\n",
      " 11  No of shares.1         4241 non-null   int64  \n",
      " 12  Market Cap             4241 non-null   float64\n",
      " 13  %age of Marketcap      4241 non-null   float64\n",
      " 14  Cap                    4241 non-null   int64  \n",
      " 15  Deviation              4241 non-null   float64\n",
      " 16  EPS                    4241 non-null   float64\n",
      " 17  ROE                    4241 non-null   float64\n",
      " 18  COA                    4241 non-null   float64\n",
      " 19  CIA                    4241 non-null   float64\n",
      " 20  CFA                    4241 non-null   float64\n",
      " 21  PBT                    4241 non-null   float64\n",
      " 22  PE                     4241 non-null   float64\n",
      " 23  Industry               4241 non-null   int64  \n",
      " 24  Result                 4241 non-null   object \n",
      " 25  code                   4241 non-null   int64  \n",
      "dtypes: float64(17), int64(7), object(2)\n",
      "memory usage: 861.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2983203324.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Symbol',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Symbol',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score as rs\n",
    "from sklearn.metrics import precision_score as ps\n",
    "from sklearn.metrics import f1_score as fs\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Shares Bought\n"
     ]
    }
   ],
   "source": [
    "print(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No of Shares Bought', 'Value of purchase', 'No of shares sold', 'Value of sale', 'No of shares', 'Value', 'Avg Price', 'Buy price', 'Nifty Index at buying', 'Nfty index at selling', 'No of shares.1', 'Market Cap', '%age of Marketcap', 'Cap', 'Deviation', 'EPS', 'ROE', 'COA', 'CIA', 'CFA', 'PBT', 'PE', 'Industry', 'code']\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for _ in data.columns:\n",
    "    if _ != 'Result':\n",
    "        features.append(_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data[features]\n",
    "y_score=data['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4241, 24)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4241,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=X_feature[3990:]\n",
    "df_y=y_score[3990:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "lrclassifier= lr()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "lrclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.44194702521784296\n",
      "Recall Score :  0.48864752017152857\n",
      "F1 Score :  0.38409285761392864\n",
      "Accuracy :  0.5465253239104829\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT  PROFIT\n",
      "1050  PROFIT  PROFIT\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.array(lrclassifier.predict(X_test))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred1']= lrclassifier.predict(X_test)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.44194702521784296\n",
      "Recall Score :  0.48864752017152857\n",
      "F1 Score :  0.38409285761392864\n",
      "Accuracy :  0.5537848605577689\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3990  PROFIT  PROFIT\n",
      "3991  PROFIT  PROFIT\n",
      "3992    LOSS  PROFIT\n",
      "3993  PROFIT  PROFIT\n",
      "3994  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(lrclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= lrclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_lr_2mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_lr_2mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_lr_2mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_lr_2mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "dtclassifier = dtc(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "dtclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.6222323324234151\n",
      "Recall Score :  0.6227895954409525\n",
      "F1 Score :  0.6224542640022516\n",
      "Accuracy :  0.6277974087161367\n",
      "\n",
      "\tTable 3\n",
      "\n",
      "      Result   pred2\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT  PROFIT\n",
      "1050  PROFIT  PROFIT\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred3 = np.array(dtclassifier.predict(X_test))\n",
    "\n",
    "p_dtc=ps(Y_test, pred3, average='macro',zero_division=1)\n",
    "r_dtc=rs(Y_test, pred3, average='macro',zero_division=1)\n",
    "f1_dtc=fs(Y_test, pred3, average='macro', zero_division=1)\n",
    "ma_dtc=dtclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_dtc)\n",
    "print(\"Recall Score : \",r_dtc)\n",
    "print(\"F1 Score : \", f1_dtc)\n",
    "print(\"Accuracy : \", ma_dtc)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred2']= dtclassifier.predict(X_test)\n",
    "print('\\n\\tTable 3\\n')\n",
    "print(a.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.44194702521784296\n",
      "Recall Score :  0.48864752017152857\n",
      "F1 Score :  0.38409285761392864\n",
      "Accuracy :  0.8804780876494024\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3990  PROFIT  PROFIT\n",
      "3991  PROFIT  PROFIT\n",
      "3992    LOSS    LOSS\n",
      "3993  PROFIT    LOSS\n",
      "3994  PROFIT    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=dtclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_2mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_2mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_2mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_2mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - SUPPORT VECTOR MACHINE\n",
    "\n",
    "from sklearn import svm\n",
    "svmclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "svmclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.48199052132701425\n",
      "Recall Score :  0.49957117869435197\n",
      "F1 Score :  0.36512169312169324\n",
      "Accuracy :  0.5630153121319199\n",
      "\n",
      "\tTable 4\n",
      "\n",
      "      Result   pred3\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT  PROFIT\n",
      "1050  PROFIT  PROFIT\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred4 = np.array(svmclassifier.predict(X_test))\n",
    "\n",
    "p_svm=ps(Y_test, pred4, average='macro',zero_division=1)\n",
    "r_svm=rs(Y_test, pred4, average='macro',zero_division=1)\n",
    "f1_svm=fs(Y_test, pred4, average='macro', zero_division=1)\n",
    "ma_svm=svmclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_svm)\n",
    "print(\"Recall Score : \",r_svm)\n",
    "print(\"F1 Score : \", f1_svm)\n",
    "print(\"Accuracy : \", ma_svm)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred3']= svmclassifier.predict(X_test)\n",
    "print('\\n\\tTable 4\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.44194702521784296\n",
      "Recall Score :  0.48864752017152857\n",
      "F1 Score :  0.38409285761392864\n",
      "Accuracy :  0.5179282868525896\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3990  PROFIT  PROFIT\n",
      "3991  PROFIT    LOSS\n",
      "3992    LOSS  PROFIT\n",
      "3993  PROFIT  PROFIT\n",
      "3994  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(svmclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=svmclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= svmclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_svc_2mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_svc_2mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_svc_2mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_svc_2mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM BOOST CLASSIFIER\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_estimators=50, learning_rate=0.001, algorithm=SAMME.R, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=10, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "classifier = AdaBoostClassifier(rf,50,0.001,'SAMME.R',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                         min_samples_leaf=2),\n",
       "                   learning_rate=0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.6284866304908292\n",
      "Recall Score :  0.6181035941996276\n",
      "F1 Score :  0.6176929634730146\n",
      "Accuracy :  0.6360424028268551\n",
      "\n",
      "\tTable 5\n",
      "\n",
      "      Result   pred4\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT    LOSS\n",
      "1050  PROFIT  PROFIT\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred5 = np.array(classifier.predict(X_test))\n",
    "\n",
    "p=ps(Y_test, pred5, average='macro',zero_division=1)\n",
    "r=rs(Y_test, pred5, average='macro',zero_division=1)\n",
    "f1=fs(Y_test, pred5, average='macro', zero_division=1)\n",
    "ma=classifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p)\n",
    "print(\"Recall Score : \",r)\n",
    "print(\"F1 Score : \", f1)\n",
    "print(\"Accuracy : \", ma)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred4']= classifier.predict(X_test)\n",
    "print('\\n\\tTable 5\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.44194702521784296\n",
      "Recall Score :  0.48864752017152857\n",
      "F1 Score :  0.38409285761392864\n",
      "Accuracy :  0.7848605577689243\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3990  PROFIT  PROFIT\n",
      "3991  PROFIT  PROFIT\n",
      "3992    LOSS    LOSS\n",
      "3993  PROFIT  PROFIT\n",
      "3994  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(classifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=classifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= classifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadboost_2mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadboost_2mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadboost_2mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadboost_2mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.88"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5100753815039529\n",
      "Recall Score :  0.5092760819274389\n",
      "F1 Score :  0.5053715830439748\n",
      "Accuracy :  0.5288574793875147\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred6\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT  PROFIT\n",
      "1050  PROFIT  PROFIT\n",
      "3401  PROFIT    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred6 = np.array(knn.predict(X_test))\n",
    "\n",
    "p_knn=ps(Y_test, pred6, average='macro',zero_division=1)\n",
    "r_knn=rs(Y_test, pred6, average='macro',zero_division=1)\n",
    "f1_knn=fs(Y_test, pred6, average='macro', zero_division=1)\n",
    "ma_knn=knn.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_knn)\n",
    "print(\"Recall Score : \",r_knn)\n",
    "print(\"F1 Score : \", f1_knn)\n",
    "print(\"Accuracy : \", ma_knn)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred6']= knn.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.44194702521784296\n",
      "Recall Score :  0.48864752017152857\n",
      "F1 Score :  0.38409285761392864\n",
      "Accuracy :  0.545816733067729\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3990  PROFIT  PROFIT\n",
      "3991  PROFIT    LOSS\n",
      "3992    LOSS  PROFIT\n",
      "3993  PROFIT    LOSS\n",
      "3994  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(knn.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=knn.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= knn.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_knn_2mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_knn_2mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_knn_2mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_knn_2mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.72"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7820965842167256\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.36069277108433734\n",
      "Accuracy :  0.5641931684334511\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred7\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT  PROFIT\n",
      "1050  PROFIT  PROFIT\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred7 = np.array(perceptron.predict(X_test))\n",
    "\n",
    "p_percep=ps(Y_test, pred7, average='macro',zero_division=1)\n",
    "r_percep=rs(Y_test, pred7, average='macro',zero_division=1)\n",
    "f1_percep=fs(Y_test, pred7, average='macro', zero_division=1)\n",
    "ma_percep=perceptron.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_percep)\n",
    "print(\"Recall Score : \",r_percep)\n",
    "print(\"F1 Score : \", f1_percep)\n",
    "print(\"Accuracy : \", ma_percep)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred7']= perceptron.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.44194702521784296\n",
      "Recall Score :  0.48864752017152857\n",
      "F1 Score :  0.38409285761392864\n",
      "Accuracy :  0.5099601593625498\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3990  PROFIT  PROFIT\n",
      "3991  PROFIT  PROFIT\n",
      "3992    LOSS  PROFIT\n",
      "3993  PROFIT  PROFIT\n",
      "3994  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(perceptron.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=perceptron.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= perceptron.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_percep_2mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_percep_2mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_percep_2mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_percep_2mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.72"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7820965842167256\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.36069277108433734\n",
      "Accuracy :  0.5641931684334511\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred8\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT  PROFIT\n",
      "1050  PROFIT  PROFIT\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred8 = np.array(sgd.predict(X_test))\n",
    "\n",
    "p_sgd=ps(Y_test, pred8, average='macro',zero_division=1)\n",
    "r_sgd=rs(Y_test, pred8, average='macro',zero_division=1)\n",
    "f1_sgd=fs(Y_test, pred8, average='macro', zero_division=1)\n",
    "ma_sgd=sgd.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_sgd)\n",
    "print(\"Recall Score : \",r_sgd)\n",
    "print(\"F1 Score : \", f1_sgd)\n",
    "print(\"Accuracy : \", ma_sgd)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred8']= sgd.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ends here\n",
    "\n",
    "\n",
    "\n",
    "### starts here 6 months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            2\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result10                 0\n",
      "dtype: int64\n",
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result10                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Arnab Karmakar/Downloads/6 months.csv\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(how='any',axis=0) \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       SmallCap\n",
       "1       SmallCap\n",
       "2         MidCap\n",
       "3       SmallCap\n",
       "4       SmallCap\n",
       "          ...   \n",
       "4066    LargeCap\n",
       "4067    SmallCap\n",
       "4068    SmallCap\n",
       "4069    SmallCap\n",
       "4070      MidCap\n",
       "Name: Cap, Length: 4069, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Cap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\431695188.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Symbol',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data['code'] = pd.factorize(data['Symbol'])[0] + 1\n",
    "data.drop('Symbol',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'SmallCap':0,'MidCap':1,'LargeCap':2}\n",
    "data['Cap']=data['Cap'].map(c)\n",
    "i={}\n",
    "count=0\n",
    "for _ in data['Industry']:\n",
    "    if _ not in i:\n",
    "        i[_]=count\n",
    "        count+=1\n",
    "data['Industry']=data['Industry'].map(i)\n",
    "\n",
    "r={'PROFIT':1,'LOSS':0}\n",
    "#data['Result']=data['Result'].map(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4066    2\n",
      "4067    0\n",
      "4068    0\n",
      "4069    0\n",
      "4070    1\n",
      "Name: Cap, Length: 4069, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3695446603.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Buy Date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3695446603.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3695446603.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Row Labels',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3695446603.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3695446603.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell price',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Buy Date',1,inplace=True)\n",
    "data.drop('Sell date',1,inplace=True)\n",
    "data.drop('Row Labels',1,inplace=True)\n",
    "#data.drop('Symbol',1,inplace=True)\n",
    "data.drop('Return',1,inplace=True)\n",
    "data.drop('Sell price',1,inplace=True)\n",
    "data.drop('Result10',axis=1,inplace=True)\n",
    "#data.drop('Nifty Index at buying',axis=1,inplace=True)\n",
    "#data.drop('Nfty index at selling',axis=1,inplace=True)\n",
    "data.drop('Change in Nifty 50',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score as rs\n",
    "from sklearn.metrics import precision_score as ps\n",
    "from sklearn.metrics import f1_score as fs\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No of Shares Bought', 'Value of purchase', 'No of shares sold', 'Value of sale', 'No of shares', 'Value', 'Avg Price', 'Buy price', 'Nifty Index at buying', 'Nfty index at selling', 'No of shares.1', 'Market Cap', '%age of Marketcap', 'Cap', 'Deviation', 'EPS', 'ROE', 'COA', 'CIA', 'CFA', 'PBT', 'PE', 'Industry', 'code']\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for _ in data.columns:\n",
    "    if _ != 'Result':\n",
    "        features.append(_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data[features]\n",
    "y_score=data['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4069, 24)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4069,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=X_feature[3806:]\n",
    "df_y=y_score[3806:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "lrclassifier= lr()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "lrclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7653562653562653\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3467094703049759\n",
      "Accuracy :  0.5307125307125307\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3889  PROFIT  PROFIT\n",
      "2843    LOSS  PROFIT\n",
      "1909    LOSS  PROFIT\n",
      "2940    LOSS  PROFIT\n",
      "2435  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.array(lrclassifier.predict(X_test))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred1']= lrclassifier.predict(X_test)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "dtclassifier = dtc(max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=15)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "dtclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7022342995169082\n",
      "Recall Score :  0.7029401783982936\n",
      "F1 Score :  0.7022425374713561\n",
      "Accuracy :  0.7027027027027027\n",
      "\n",
      "\tTable 3\n",
      "\n",
      "      Result   pred2\n",
      "3889  PROFIT    LOSS\n",
      "2843    LOSS  PROFIT\n",
      "1909    LOSS    LOSS\n",
      "2940    LOSS    LOSS\n",
      "2435  PROFIT    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred3 = np.array(dtclassifier.predict(X_test))\n",
    "\n",
    "p_dtc=ps(Y_test, pred3, average='macro',zero_division=1)\n",
    "r_dtc=rs(Y_test, pred3, average='macro',zero_division=1)\n",
    "f1_dtc=fs(Y_test, pred3, average='macro', zero_division=1)\n",
    "ma_dtc=dtclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_dtc)\n",
    "print(\"Recall Score : \",r_dtc)\n",
    "print(\"F1 Score : \", f1_dtc)\n",
    "print(\"Accuracy : \", ma_dtc)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred2']= dtclassifier.predict(X_test)\n",
    "print('\\n\\tTable 3\\n')\n",
    "print(a.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7653562653562653\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3467094703049759\n",
      "Accuracy :  0.7338403041825095\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3808  PROFIT  PROFIT\n",
      "3809  PROFIT  PROFIT\n",
      "3810  PROFIT  PROFIT\n",
      "3811  PROFIT  PROFIT\n",
      "3812  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_6mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_6mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - SUPPORT VECTOR MACHINE\n",
    "\n",
    "from sklearn import svm\n",
    "svmclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "svmclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7653562653562653\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3467094703049759\n",
      "Accuracy :  0.5307125307125307\n",
      "\n",
      "\tTable 4\n",
      "\n",
      "      Result   pred3\n",
      "3889  PROFIT  PROFIT\n",
      "2843    LOSS  PROFIT\n",
      "1909    LOSS  PROFIT\n",
      "2940    LOSS  PROFIT\n",
      "2435  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred4 = np.array(svmclassifier.predict(X_test))\n",
    "\n",
    "p_svm=ps(Y_test, pred4, average='macro',zero_division=1)\n",
    "r_svm=rs(Y_test, pred4, average='macro',zero_division=1)\n",
    "f1_svm=fs(Y_test, pred4, average='macro', zero_division=1)\n",
    "ma_svm=svmclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_svm)\n",
    "print(\"Recall Score : \",r_svm)\n",
    "print(\"F1 Score : \", f1_svm)\n",
    "print(\"Accuracy : \", ma_svm)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred3']= svmclassifier.predict(X_test)\n",
    "print('\\n\\tTable 4\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM BOOST CLASSIFIER\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_estimators=50, learning_rate=0.001, algorithm=SAMME.R, random_state=10 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=2, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "classifier = AdaBoostClassifier(rf,50,0.001,'SAMME.R',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=2,\n",
       "                                                         min_samples_leaf=2),\n",
       "                   learning_rate=0.001, random_state=10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.6842982252189413\n",
      "Recall Score :  0.6585102772929998\n",
      "F1 Score :  0.6527408394192418\n",
      "Accuracy :  0.6695331695331695\n",
      "\n",
      "\tTable 5\n",
      "\n",
      "      Result   pred4\n",
      "3889  PROFIT  PROFIT\n",
      "2843    LOSS    LOSS\n",
      "1909    LOSS  PROFIT\n",
      "2940    LOSS    LOSS\n",
      "2435  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred5 = np.array(classifier.predict(X_test))\n",
    "\n",
    "p=ps(Y_test, pred5, average='macro',zero_division=1)\n",
    "r=rs(Y_test, pred5, average='macro',zero_division=1)\n",
    "f1=fs(Y_test, pred5, average='macro', zero_division=1)\n",
    "ma=classifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p)\n",
    "print(\"Recall Score : \",r)\n",
    "print(\"F1 Score : \", f1)\n",
    "print(\"Accuracy : \", ma)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred4']= classifier.predict(X_test)\n",
    "print('\\n\\tTable 5\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7653562653562653\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3467094703049759\n",
      "Accuracy :  0.7338403041825095\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3808  PROFIT  PROFIT\n",
      "3809  PROFIT  PROFIT\n",
      "3810  PROFIT  PROFIT\n",
      "3811  PROFIT  PROFIT\n",
      "3812  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(classifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=classifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= classifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadaboost_6mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadaboost_6mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.8"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5254065040650406\n",
      "Recall Score :  0.5243903917006011\n",
      "F1 Score :  0.521983225108225\n",
      "Accuracy :  0.5307125307125307\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred6\n",
      "3889  PROFIT  PROFIT\n",
      "2843    LOSS  PROFIT\n",
      "1909    LOSS  PROFIT\n",
      "2940    LOSS  PROFIT\n",
      "2435  PROFIT    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred6 = np.array(knn.predict(X_test))\n",
    "\n",
    "p_knn=ps(Y_test, pred6, average='macro',zero_division=1)\n",
    "r_knn=rs(Y_test, pred6, average='macro',zero_division=1)\n",
    "f1_knn=fs(Y_test, pred6, average='macro', zero_division=1)\n",
    "ma_knn=knn.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_knn)\n",
    "print(\"Recall Score : \",r_knn)\n",
    "print(\"F1 Score : \", f1_knn)\n",
    "print(\"Accuracy : \", ma_knn)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred6']= knn.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.07"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.6307596513075966\n",
      "Recall Score :  0.5069989819662595\n",
      "F1 Score :  0.36772465514932373\n",
      "Accuracy :  0.5368550368550369\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred7\n",
      "3889  PROFIT  PROFIT\n",
      "2843    LOSS  PROFIT\n",
      "1909    LOSS  PROFIT\n",
      "2940    LOSS  PROFIT\n",
      "2435  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred7 = np.array(perceptron.predict(X_test))\n",
    "\n",
    "p_percep=ps(Y_test, pred7, average='macro',zero_division=1)\n",
    "r_percep=rs(Y_test, pred7, average='macro',zero_division=1)\n",
    "f1_percep=fs(Y_test, pred7, average='macro', zero_division=1)\n",
    "ma_percep=perceptron.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_percep)\n",
    "print(\"Recall Score : \",r_percep)\n",
    "print(\"F1 Score : \", f1_percep)\n",
    "print(\"Accuracy : \", ma_percep)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred7']= perceptron.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.93"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7346437346437347\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3193979933110368\n",
      "Accuracy :  0.4692874692874693\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result pred8\n",
      "3889  PROFIT  LOSS\n",
      "2843    LOSS  LOSS\n",
      "1909    LOSS  LOSS\n",
      "2940    LOSS  LOSS\n",
      "2435  PROFIT  LOSS\n"
     ]
    }
   ],
   "source": [
    "pred8 = np.array(sgd.predict(X_test))\n",
    "\n",
    "p_sgd=ps(Y_test, pred8, average='macro',zero_division=1)\n",
    "r_sgd=rs(Y_test, pred8, average='macro',zero_division=1)\n",
    "f1_sgd=fs(Y_test, pred8, average='macro', zero_division=1)\n",
    "ma_sgd=sgd.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_sgd)\n",
    "print(\"Recall Score : \",r_sgd)\n",
    "print(\"F1 Score : \", f1_sgd)\n",
    "print(\"Accuracy : \", ma_sgd)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred8']= sgd.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ends here\n",
    "\n",
    "# 9 months start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            2\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result13                 0\n",
      "dtype: int64\n",
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result13                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Arnab Karmakar/Downloads/9 months.csv\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(how='any',axis=0) \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3930 entries, 0 to 3931\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Row Labels             3930 non-null   object \n",
      " 1   Symbol                 3930 non-null   object \n",
      " 2   No of Shares Bought    3930 non-null   int64  \n",
      " 3   Value of purchase      3930 non-null   float64\n",
      " 4   No of shares sold      3930 non-null   int64  \n",
      " 5   Value of sale          3930 non-null   float64\n",
      " 6   No of shares           3930 non-null   int64  \n",
      " 7   Value                  3930 non-null   float64\n",
      " 8   Avg Price              3930 non-null   float64\n",
      " 9   Buy Date               3930 non-null   object \n",
      " 10  Sell date              3930 non-null   object \n",
      " 11  Buy price              3930 non-null   float64\n",
      " 12  Sell price             3930 non-null   float64\n",
      " 13  Nifty Index at buying  3930 non-null   float64\n",
      " 14  Nfty index at selling  3930 non-null   float64\n",
      " 15  Change in Nifty 50     3930 non-null   object \n",
      " 16  Return                 3930 non-null   float64\n",
      " 17  No of shares.1         3930 non-null   int64  \n",
      " 18  Market Cap             3930 non-null   float64\n",
      " 19  %age of Marketcap      3930 non-null   float64\n",
      " 20  Cap                    3930 non-null   object \n",
      " 21  Deviation              3930 non-null   float64\n",
      " 22  EPS                    3930 non-null   float64\n",
      " 23  ROE                    3930 non-null   float64\n",
      " 24  COA                    3930 non-null   float64\n",
      " 25  CIA                    3930 non-null   float64\n",
      " 26  CFA                    3930 non-null   float64\n",
      " 27  PBT                    3930 non-null   float64\n",
      " 28  PE                     3930 non-null   float64\n",
      " 29  Industry               3930 non-null   object \n",
      " 30  Result                 3930 non-null   object \n",
      " 31  Result13               3930 non-null   object \n",
      "dtypes: float64(19), int64(4), object(9)\n",
      "memory usage: 1013.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'SmallCap':0,'MidCap':1,'LargeCap':2}\n",
    "data['Cap']=data['Cap'].map(c)\n",
    "i={}\n",
    "count=0\n",
    "for _ in data['Industry']:\n",
    "    if _ not in i:\n",
    "        i[_]=count\n",
    "        count+=1\n",
    "data['Industry']=data['Industry'].map(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3927    0\n",
      "3928    0\n",
      "3929    0\n",
      "3930    1\n",
      "3931    0\n",
      "Name: Cap, Length: 3930, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "        ..\n",
      "3927    13\n",
      "3928     0\n",
      "3929    22\n",
      "3930    94\n",
      "3931     8\n",
      "Name: Industry, Length: 3930, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2471895391.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Buy Date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2471895391.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2471895391.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Row Labels',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2471895391.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2471895391.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell price',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Buy Date',1,inplace=True)\n",
    "data.drop('Sell date',1,inplace=True)\n",
    "data.drop('Row Labels',1,inplace=True)\n",
    "#data.drop('Symbol',1,inplace=True)\n",
    "data.drop('Return',1,inplace=True)\n",
    "data.drop('Sell price',1,inplace=True)\n",
    "data.drop('Result13',axis=1,inplace=True)\n",
    "#data.drop('Nifty Index at buying',axis=1,inplace=True)\n",
    "#data.drop('Nfty index at selling',axis=1,inplace=True)\n",
    "data.drop('Change in Nifty 50',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code'] = pd.factorize(data['Symbol'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3930 entries, 0 to 3931\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Symbol                 3930 non-null   object \n",
      " 1   No of Shares Bought    3930 non-null   int64  \n",
      " 2   Value of purchase      3930 non-null   float64\n",
      " 3   No of shares sold      3930 non-null   int64  \n",
      " 4   Value of sale          3930 non-null   float64\n",
      " 5   No of shares           3930 non-null   int64  \n",
      " 6   Value                  3930 non-null   float64\n",
      " 7   Avg Price              3930 non-null   float64\n",
      " 8   Buy price              3930 non-null   float64\n",
      " 9   Nifty Index at buying  3930 non-null   float64\n",
      " 10  Nfty index at selling  3930 non-null   float64\n",
      " 11  No of shares.1         3930 non-null   int64  \n",
      " 12  Market Cap             3930 non-null   float64\n",
      " 13  %age of Marketcap      3930 non-null   float64\n",
      " 14  Cap                    3930 non-null   int64  \n",
      " 15  Deviation              3930 non-null   float64\n",
      " 16  EPS                    3930 non-null   float64\n",
      " 17  ROE                    3930 non-null   float64\n",
      " 18  COA                    3930 non-null   float64\n",
      " 19  CIA                    3930 non-null   float64\n",
      " 20  CFA                    3930 non-null   float64\n",
      " 21  PBT                    3930 non-null   float64\n",
      " 22  PE                     3930 non-null   float64\n",
      " 23  Industry               3930 non-null   int64  \n",
      " 24  Result                 3930 non-null   object \n",
      " 25  code                   3930 non-null   int64  \n",
      "dtypes: float64(17), int64(7), object(2)\n",
      "memory usage: 829.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2983203324.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Symbol',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Symbol',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score as rs\n",
    "from sklearn.metrics import precision_score as ps\n",
    "from sklearn.metrics import f1_score as fs\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Shares Bought\n"
     ]
    }
   ],
   "source": [
    "print(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No of Shares Bought', 'Value of purchase', 'No of shares sold', 'Value of sale', 'No of shares', 'Value', 'Avg Price', 'Buy price', 'Nifty Index at buying', 'Nfty index at selling', 'No of shares.1', 'Market Cap', '%age of Marketcap', 'Cap', 'Deviation', 'EPS', 'ROE', 'COA', 'CIA', 'CFA', 'PBT', 'PE', 'Industry', 'code']\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for _ in data.columns:\n",
    "    if _ != 'Result':\n",
    "        features.append(_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data[features]\n",
    "y_score=data['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3930, 24)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3930,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=X_feature[3718:]\n",
    "df_y=y_score[3718:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "lrclassifier= lr()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "lrclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7767175572519084\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.35626535626535627\n",
      "Accuracy :  0.5534351145038168\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "1527    LOSS  PROFIT\n",
      "634   PROFIT  PROFIT\n",
      "2278  PROFIT  PROFIT\n",
      "794   PROFIT  PROFIT\n",
      "2626    LOSS  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.array(lrclassifier.predict(X_test))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred1']= lrclassifier.predict(X_test)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_lr_9mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_lr_9mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "dtclassifier = dtc(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "dtclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7508529761556608\n",
      "Recall Score :  0.7528047941841045\n",
      "F1 Score :  0.7514280125195618\n",
      "Accuracy :  0.7531806615776081\n",
      "\n",
      "\tTable 3\n",
      "\n",
      "      Result   pred2\n",
      "1527    LOSS    LOSS\n",
      "634   PROFIT  PROFIT\n",
      "2278  PROFIT    LOSS\n",
      "794   PROFIT  PROFIT\n",
      "2626    LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred3 = np.array(dtclassifier.predict(X_test))\n",
    "\n",
    "p_dtc=ps(Y_test, pred3, average='macro',zero_division=1)\n",
    "r_dtc=rs(Y_test, pred3, average='macro',zero_division=1)\n",
    "f1_dtc=fs(Y_test, pred3, average='macro', zero_division=1)\n",
    "ma_dtc=dtclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_dtc)\n",
    "print(\"Recall Score : \",r_dtc)\n",
    "print(\"F1 Score : \", f1_dtc)\n",
    "print(\"Accuracy : \", ma_dtc)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred2']= dtclassifier.predict(X_test)\n",
    "print('\\n\\tTable 3\\n')\n",
    "print(a.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7767175572519084\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.35626535626535627\n",
      "Accuracy :  0.9622641509433962\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3720    LOSS    LOSS\n",
      "3721    LOSS    LOSS\n",
      "3722  PROFIT  PROFIT\n",
      "3723  PROFIT  PROFIT\n",
      "3724  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=dtclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_9mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_9mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_9mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_9mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - SUPPORT VECTOR MACHINE\n",
    "\n",
    "from sklearn import svm\n",
    "svmclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "svmclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7767175572519084\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.35626535626535627\n",
      "Accuracy :  0.5534351145038168\n",
      "\n",
      "\tTable 4\n",
      "\n",
      "      Result   pred3\n",
      "1527    LOSS  PROFIT\n",
      "634   PROFIT  PROFIT\n",
      "2278  PROFIT  PROFIT\n",
      "794   PROFIT  PROFIT\n",
      "2626    LOSS  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred4 = np.array(svmclassifier.predict(X_test))\n",
    "\n",
    "p_svm=ps(Y_test, pred4, average='macro',zero_division=1)\n",
    "r_svm=rs(Y_test, pred4, average='macro',zero_division=1)\n",
    "f1_svm=fs(Y_test, pred4, average='macro', zero_division=1)\n",
    "ma_svm=svmclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_svm)\n",
    "print(\"Recall Score : \",r_svm)\n",
    "print(\"F1 Score : \", f1_svm)\n",
    "print(\"Accuracy : \", ma_svm)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred3']= svmclassifier.predict(X_test)\n",
    "print('\\n\\tTable 4\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_svc_9mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_svc_9mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM BOOST CLASSIFIER\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_estimators=50, learning_rate=0.001, algorithm=SAMME.R, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=10, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "classifier = AdaBoostClassifier(rf,50,0.001,'SAMME.R',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                         min_samples_leaf=2),\n",
       "                   learning_rate=0.001)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7905952937509739\n",
      "Recall Score :  0.7931132724236172\n",
      "F1 Score :  0.7912799534722326\n",
      "Accuracy :  0.7926208651399491\n",
      "\n",
      "\tTable 5\n",
      "\n",
      "      Result   pred4\n",
      "1527    LOSS    LOSS\n",
      "634   PROFIT  PROFIT\n",
      "2278  PROFIT  PROFIT\n",
      "794   PROFIT  PROFIT\n",
      "2626    LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred5 = np.array(classifier.predict(X_test))\n",
    "\n",
    "p=ps(Y_test, pred5, average='macro',zero_division=1)\n",
    "r=rs(Y_test, pred5, average='macro',zero_division=1)\n",
    "f1=fs(Y_test, pred5, average='macro', zero_division=1)\n",
    "ma=classifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p)\n",
    "print(\"Recall Score : \",r)\n",
    "print(\"F1 Score : \", f1)\n",
    "print(\"Accuracy : \", ma)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred4']= classifier.predict(X_test)\n",
    "print('\\n\\tTable 5\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7767175572519084\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.35626535626535627\n",
      "Accuracy :  0.8962264150943396\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3720    LOSS  PROFIT\n",
      "3721    LOSS  PROFIT\n",
      "3722  PROFIT  PROFIT\n",
      "3723  PROFIT  PROFIT\n",
      "3724  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(classifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=classifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= classifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadaboost_9mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadaboost_9mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadboost_9mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadboost_9mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.49"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.569230141513604\n",
      "Recall Score :  0.5666764908144218\n",
      "F1 Score :  0.5661011087241359\n",
      "Accuracy :  0.5776081424936387\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred6\n",
      "1527    LOSS  PROFIT\n",
      "634   PROFIT    LOSS\n",
      "2278  PROFIT  PROFIT\n",
      "794   PROFIT  PROFIT\n",
      "2626    LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred6 = np.array(knn.predict(X_test))\n",
    "\n",
    "p_knn=ps(Y_test, pred6, average='macro',zero_division=1)\n",
    "r_knn=rs(Y_test, pred6, average='macro',zero_division=1)\n",
    "f1_knn=fs(Y_test, pred6, average='macro', zero_division=1)\n",
    "ma_knn=knn.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_knn)\n",
    "print(\"Recall Score : \",r_knn)\n",
    "print(\"F1 Score : \", f1_knn)\n",
    "print(\"Accuracy : \", ma_knn)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred6']= knn.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_knn_9mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_knn_9mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.32"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7232824427480916\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3087071240105541\n",
      "Accuracy :  0.44656488549618323\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result pred7\n",
      "1527    LOSS  LOSS\n",
      "634   PROFIT  LOSS\n",
      "2278  PROFIT  LOSS\n",
      "794   PROFIT  LOSS\n",
      "2626    LOSS  LOSS\n"
     ]
    }
   ],
   "source": [
    "pred7 = np.array(perceptron.predict(X_test))\n",
    "\n",
    "p_percep=ps(Y_test, pred7, average='macro',zero_division=1)\n",
    "r_percep=rs(Y_test, pred7, average='macro',zero_division=1)\n",
    "f1_percep=fs(Y_test, pred7, average='macro', zero_division=1)\n",
    "ma_percep=perceptron.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_percep)\n",
    "print(\"Recall Score : \",r_percep)\n",
    "print(\"F1 Score : \", f1_percep)\n",
    "print(\"Accuracy : \", ma_percep)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred7']= perceptron.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_percep_9mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_percep_9mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.68"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.6532776349614395\n",
      "Recall Score :  0.5062481579722959\n",
      "F1 Score :  0.3736792914273642\n",
      "Accuracy :  0.5585241730279898\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred8\n",
      "1527    LOSS  PROFIT\n",
      "634   PROFIT  PROFIT\n",
      "2278  PROFIT  PROFIT\n",
      "794   PROFIT  PROFIT\n",
      "2626    LOSS  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred8 = np.array(sgd.predict(X_test))\n",
    "\n",
    "p_sgd=ps(Y_test, pred8, average='macro',zero_division=1)\n",
    "r_sgd=rs(Y_test, pred8, average='macro',zero_division=1)\n",
    "f1_sgd=fs(Y_test, pred8, average='macro', zero_division=1)\n",
    "ma_sgd=sgd.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_sgd)\n",
    "print(\"Recall Score : \",r_sgd)\n",
    "print(\"F1 Score : \", f1_sgd)\n",
    "print(\"Accuracy : \", ma_sgd)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred8']= sgd.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end here\n",
    "\n",
    "#12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            2\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result15                 0\n",
      "dtype: int64\n",
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result15                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Arnab Karmakar/Downloads/12_months.csv\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(how='any',axis=0) \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3800 entries, 0 to 3801\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Row Labels             3800 non-null   object \n",
      " 1   Symbol                 3800 non-null   object \n",
      " 2   No of Shares Bought    3800 non-null   int64  \n",
      " 3   Value of purchase      3800 non-null   float64\n",
      " 4   No of shares sold      3800 non-null   int64  \n",
      " 5   Value of sale          3800 non-null   float64\n",
      " 6   No of shares           3800 non-null   int64  \n",
      " 7   Value                  3800 non-null   float64\n",
      " 8   Avg Price              3800 non-null   float64\n",
      " 9   Buy Date               3800 non-null   object \n",
      " 10  Sell date              3800 non-null   object \n",
      " 11  Buy price              3800 non-null   float64\n",
      " 12  Sell price             3800 non-null   float64\n",
      " 13  Nifty Index at buying  3800 non-null   float64\n",
      " 14  Nfty index at selling  3800 non-null   float64\n",
      " 15  Change in Nifty 50     3800 non-null   object \n",
      " 16  Return                 3800 non-null   float64\n",
      " 17  No of shares.1         3800 non-null   int64  \n",
      " 18  Market Cap             3800 non-null   float64\n",
      " 19  %age of Marketcap      3800 non-null   float64\n",
      " 20  Cap                    3800 non-null   object \n",
      " 21  Deviation              3800 non-null   float64\n",
      " 22  EPS                    3800 non-null   float64\n",
      " 23  ROE                    3800 non-null   float64\n",
      " 24  COA                    3800 non-null   float64\n",
      " 25  CIA                    3800 non-null   float64\n",
      " 26  CFA                    3800 non-null   float64\n",
      " 27  PBT                    3800 non-null   float64\n",
      " 28  PE                     3800 non-null   float64\n",
      " 29  Industry               3800 non-null   object \n",
      " 30  Result                 3800 non-null   object \n",
      " 31  Result15               3800 non-null   object \n",
      "dtypes: float64(19), int64(4), object(9)\n",
      "memory usage: 979.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'SmallCap':0,'MidCap':1,'LargeCap':2}\n",
    "data['Cap']=data['Cap'].map(c)\n",
    "i={}\n",
    "count=0\n",
    "for _ in data['Industry']:\n",
    "    if _ not in i:\n",
    "        i[_]=count\n",
    "        count+=1\n",
    "data['Industry']=data['Industry'].map(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3797    0\n",
      "3798    0\n",
      "3799    0\n",
      "3800    0\n",
      "3801    0\n",
      "Name: Cap, Length: 3800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "        ..\n",
      "3797    36\n",
      "3798    66\n",
      "3799    13\n",
      "3800    13\n",
      "3801    14\n",
      "Name: Industry, Length: 3800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\1835544499.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Buy Date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\1835544499.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\1835544499.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Row Labels',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\1835544499.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\1835544499.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell price',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Buy Date',1,inplace=True)\n",
    "data.drop('Sell date',1,inplace=True)\n",
    "data.drop('Row Labels',1,inplace=True)\n",
    "#data.drop('Symbol',1,inplace=True)\n",
    "data.drop('Return',1,inplace=True)\n",
    "data.drop('Sell price',1,inplace=True)\n",
    "data.drop('Result15',axis=1,inplace=True)\n",
    "#data.drop('Nifty Index at buying',axis=1,inplace=True)\n",
    "#data.drop('Nfty index at selling',axis=1,inplace=True)\n",
    "data.drop('Change in Nifty 50',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code'] = pd.factorize(data['Symbol'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3800 entries, 0 to 3801\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Symbol                 3800 non-null   object \n",
      " 1   No of Shares Bought    3800 non-null   int64  \n",
      " 2   Value of purchase      3800 non-null   float64\n",
      " 3   No of shares sold      3800 non-null   int64  \n",
      " 4   Value of sale          3800 non-null   float64\n",
      " 5   No of shares           3800 non-null   int64  \n",
      " 6   Value                  3800 non-null   float64\n",
      " 7   Avg Price              3800 non-null   float64\n",
      " 8   Buy price              3800 non-null   float64\n",
      " 9   Nifty Index at buying  3800 non-null   float64\n",
      " 10  Nfty index at selling  3800 non-null   float64\n",
      " 11  No of shares.1         3800 non-null   int64  \n",
      " 12  Market Cap             3800 non-null   float64\n",
      " 13  %age of Marketcap      3800 non-null   float64\n",
      " 14  Cap                    3800 non-null   int64  \n",
      " 15  Deviation              3800 non-null   float64\n",
      " 16  EPS                    3800 non-null   float64\n",
      " 17  ROE                    3800 non-null   float64\n",
      " 18  COA                    3800 non-null   float64\n",
      " 19  CIA                    3800 non-null   float64\n",
      " 20  CFA                    3800 non-null   float64\n",
      " 21  PBT                    3800 non-null   float64\n",
      " 22  PE                     3800 non-null   float64\n",
      " 23  Industry               3800 non-null   int64  \n",
      " 24  Result                 3800 non-null   object \n",
      " 25  code                   3800 non-null   int64  \n",
      "dtypes: float64(17), int64(7), object(2)\n",
      "memory usage: 801.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2983203324.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Symbol',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Symbol',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score as rs\n",
    "from sklearn.metrics import precision_score as ps\n",
    "from sklearn.metrics import f1_score as fs\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Shares Bought\n"
     ]
    }
   ],
   "source": [
    "print(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No of Shares Bought', 'Value of purchase', 'No of shares sold', 'Value of sale', 'No of shares', 'Value', 'Avg Price', 'Buy price', 'Nifty Index at buying', 'Nfty index at selling', 'No of shares.1', 'Market Cap', '%age of Marketcap', 'Cap', 'Deviation', 'EPS', 'ROE', 'COA', 'CIA', 'CFA', 'PBT', 'PE', 'Industry', 'code']\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for _ in data.columns:\n",
    "    if _ != 'Result':\n",
    "        features.append(_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data[features]\n",
    "y_score=data['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800, 24)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800,)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=X_feature[3508:]\n",
    "df_y=y_score[3508:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "lrclassifier= lr()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "lrclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7848684210526315\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3629505448449288\n",
      "Accuracy :  0.5697368421052632\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3179  PROFIT  PROFIT\n",
      "2132    LOSS  PROFIT\n",
      "911   PROFIT  PROFIT\n",
      "1012    LOSS  PROFIT\n",
      "1023  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.array(lrclassifier.predict(X_test))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred1']= lrclassifier.predict(X_test)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_lr_12mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_lr_12mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "dtclassifier = dtc(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "dtclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7576652425232471\n",
      "Recall Score :  0.7606733478822807\n",
      "F1 Score :  0.7586797910990807\n",
      "Accuracy :  0.7618421052631579\n",
      "\n",
      "\tTable 3\n",
      "\n",
      "      Result   pred2\n",
      "3179  PROFIT  PROFIT\n",
      "2132    LOSS  PROFIT\n",
      "911   PROFIT  PROFIT\n",
      "1012    LOSS    LOSS\n",
      "1023  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred3 = np.array(dtclassifier.predict(X_test))\n",
    "\n",
    "p_dtc=ps(Y_test, pred3, average='macro',zero_division=1)\n",
    "r_dtc=rs(Y_test, pred3, average='macro',zero_division=1)\n",
    "f1_dtc=fs(Y_test, pred3, average='macro', zero_division=1)\n",
    "ma_dtc=dtclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_dtc)\n",
    "print(\"Recall Score : \",r_dtc)\n",
    "print(\"F1 Score : \", f1_dtc)\n",
    "print(\"Accuracy : \", ma_dtc)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred2']= dtclassifier.predict(X_test)\n",
    "print('\\n\\tTable 3\\n')\n",
    "print(a.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7848684210526315\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3629505448449288\n",
      "Accuracy :  0.952054794520548\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3510  PROFIT  PROFIT\n",
      "3511  PROFIT  PROFIT\n",
      "3512  PROFIT  PROFIT\n",
      "3513  PROFIT  PROFIT\n",
      "3514  PROFIT    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=dtclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_12mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_12mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_12mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_12mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - SUPPORT VECTOR MACHINE\n",
    "\n",
    "from sklearn import svm\n",
    "svmclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "svmclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7848684210526315\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3629505448449288\n",
      "Accuracy :  0.5697368421052632\n",
      "\n",
      "\tTable 4\n",
      "\n",
      "      Result   pred3\n",
      "3179  PROFIT  PROFIT\n",
      "2132    LOSS  PROFIT\n",
      "911   PROFIT  PROFIT\n",
      "1012    LOSS  PROFIT\n",
      "1023  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred4 = np.array(svmclassifier.predict(X_test))\n",
    "\n",
    "p_svm=ps(Y_test, pred4, average='macro',zero_division=1)\n",
    "r_svm=rs(Y_test, pred4, average='macro',zero_division=1)\n",
    "f1_svm=fs(Y_test, pred4, average='macro', zero_division=1)\n",
    "ma_svm=svmclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_svm)\n",
    "print(\"Recall Score : \",r_svm)\n",
    "print(\"F1 Score : \", f1_svm)\n",
    "print(\"Accuracy : \", ma_svm)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred3']= svmclassifier.predict(X_test)\n",
    "print('\\n\\tTable 4\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_svc_12mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_svc_12mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM BOOST CLASSIFIER\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_estimators=50, learning_rate=0.001, algorithm=SAMME.R, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=10, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "classifier = AdaBoostClassifier(rf,50,0.001,'SAMME.R',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                         min_samples_leaf=2),\n",
       "                   learning_rate=0.001)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.8261574222165355\n",
      "Recall Score :  0.8240566137678242\n",
      "F1 Score :  0.8250100955714094\n",
      "Accuracy :  0.8289473684210527\n",
      "\n",
      "\tTable 5\n",
      "\n",
      "      Result   pred4\n",
      "3179  PROFIT  PROFIT\n",
      "2132    LOSS    LOSS\n",
      "911   PROFIT    LOSS\n",
      "1012    LOSS    LOSS\n",
      "1023  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred5 = np.array(classifier.predict(X_test))\n",
    "\n",
    "p=ps(Y_test, pred5, average='macro',zero_division=1)\n",
    "r=rs(Y_test, pred5, average='macro',zero_division=1)\n",
    "f1=fs(Y_test, pred5, average='macro', zero_division=1)\n",
    "ma=classifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p)\n",
    "print(\"Recall Score : \",r)\n",
    "print(\"F1 Score : \", f1)\n",
    "print(\"Accuracy : \", ma)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred4']= classifier.predict(X_test)\n",
    "print('\\n\\tTable 5\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7848684210526315\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3629505448449288\n",
      "Accuracy :  0.952054794520548\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "      Result   pred1\n",
      "3510  PROFIT  PROFIT\n",
      "3511  PROFIT  PROFIT\n",
      "3512  PROFIT  PROFIT\n",
      "3513  PROFIT  PROFIT\n",
      "3514  PROFIT    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=dtclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadaboost_12mon_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadaboost_12mon_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadboost_12mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadboost_12mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.85"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5665178571428571\n",
      "Recall Score :  0.5631396063309109\n",
      "F1 Score :  0.5625334947698537\n",
      "Accuracy :  0.5802631578947368\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred6\n",
      "3179  PROFIT  PROFIT\n",
      "2132    LOSS  PROFIT\n",
      "911   PROFIT  PROFIT\n",
      "1012    LOSS    LOSS\n",
      "1023  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred6 = np.array(knn.predict(X_test))\n",
    "\n",
    "p_knn=ps(Y_test, pred6, average='macro',zero_division=1)\n",
    "r_knn=rs(Y_test, pred6, average='macro',zero_division=1)\n",
    "f1_knn=fs(Y_test, pred6, average='macro', zero_division=1)\n",
    "ma_knn=knn.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_knn)\n",
    "print(\"Recall Score : \",r_knn)\n",
    "print(\"F1 Score : \", f1_knn)\n",
    "print(\"Accuracy : \", ma_knn)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred6']= knn.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_knn_12mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_knn_12mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.53"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5712388541073801\n",
      "Recall Score :  0.502652004717814\n",
      "F1 Score :  0.374539285678222\n",
      "Accuracy :  0.5710526315789474\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred7\n",
      "3179  PROFIT  PROFIT\n",
      "2132    LOSS  PROFIT\n",
      "911   PROFIT  PROFIT\n",
      "1012    LOSS  PROFIT\n",
      "1023  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred7 = np.array(perceptron.predict(X_test))\n",
    "\n",
    "p_percep=ps(Y_test, pred7, average='macro',zero_division=1)\n",
    "r_percep=rs(Y_test, pred7, average='macro',zero_division=1)\n",
    "f1_percep=fs(Y_test, pred7, average='macro', zero_division=1)\n",
    "ma_percep=perceptron.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_percep)\n",
    "print(\"Recall Score : \",r_percep)\n",
    "print(\"F1 Score : \", f1_percep)\n",
    "print(\"Accuracy : \", ma_percep)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred7']= perceptron.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_percep_12mon.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_percep_12mon.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.39"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5123194562446899\n",
      "Recall Score :  0.5007168534723252\n",
      "F1 Score :  0.3760450144675057\n",
      "Accuracy :  0.5684210526315789\n",
      "\n",
      "\tTable\n",
      "\n",
      "      Result   pred8\n",
      "3179  PROFIT  PROFIT\n",
      "2132    LOSS  PROFIT\n",
      "911   PROFIT  PROFIT\n",
      "1012    LOSS  PROFIT\n",
      "1023  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred8 = np.array(sgd.predict(X_test))\n",
    "\n",
    "p_sgd=ps(Y_test, pred8, average='macro',zero_division=1)\n",
    "r_sgd=rs(Y_test, pred8, average='macro',zero_division=1)\n",
    "f1_sgd=fs(Y_test, pred8, average='macro', zero_division=1)\n",
    "ma_sgd=sgd.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_sgd)\n",
    "print(\"Recall Score : \",r_sgd)\n",
    "print(\"F1 Score : \", f1_sgd)\n",
    "print(\"Accuracy : \", ma_sgd)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred8']= sgd.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end here\n",
    "\n",
    "#2 months 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result5                  0\n",
      "dtype: int64\n",
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result5                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Arnab Karmakar/Downloads/2 month.csv\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(how='any',axis=0) \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4241 entries, 0 to 4240\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Row Labels             4241 non-null   object \n",
      " 1   Symbol                 4241 non-null   object \n",
      " 2   No of Shares Bought    4241 non-null   int64  \n",
      " 3   Value of purchase      4241 non-null   float64\n",
      " 4   No of shares sold      4241 non-null   int64  \n",
      " 5   Value of sale          4241 non-null   float64\n",
      " 6   No of shares           4241 non-null   int64  \n",
      " 7   Value                  4241 non-null   float64\n",
      " 8   Avg Price              4241 non-null   float64\n",
      " 9   Buy Date               4241 non-null   object \n",
      " 10  Sell date              4241 non-null   object \n",
      " 11  Buy price              4241 non-null   float64\n",
      " 12  Sell price             4241 non-null   float64\n",
      " 13  Nifty Index at buying  4241 non-null   float64\n",
      " 14  Nfty index at selling  4241 non-null   float64\n",
      " 15  Change in Nifty 50     4241 non-null   object \n",
      " 16  Return                 4241 non-null   float64\n",
      " 17  No of shares.1         4241 non-null   int64  \n",
      " 18  Market Cap             4241 non-null   float64\n",
      " 19  %age of Marketcap      4241 non-null   float64\n",
      " 20  Cap                    4241 non-null   object \n",
      " 21  Deviation              4241 non-null   float64\n",
      " 22  EPS                    4241 non-null   float64\n",
      " 23  ROE                    4241 non-null   float64\n",
      " 24  COA                    4241 non-null   float64\n",
      " 25  CIA                    4241 non-null   float64\n",
      " 26  CFA                    4241 non-null   float64\n",
      " 27  PBT                    4241 non-null   float64\n",
      " 28  PE                     4241 non-null   float64\n",
      " 29  Industry               4241 non-null   object \n",
      " 30  Result                 4241 non-null   object \n",
      " 31  Result5                4241 non-null   object \n",
      "dtypes: float64(19), int64(4), object(9)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'SmallCap':0,'MidCap':1,'LargeCap':2}\n",
    "data['Cap']=data['Cap'].map(c)\n",
    "i={}\n",
    "count=0\n",
    "for _ in data['Industry']:\n",
    "    if _ not in i:\n",
    "        i[_]=count\n",
    "        count+=1\n",
    "data['Industry']=data['Industry'].map(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4236    0\n",
      "4237    0\n",
      "4238    0\n",
      "4239    0\n",
      "4240    0\n",
      "Name: Cap, Length: 4241, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "        ..\n",
      "4236    56\n",
      "4237     0\n",
      "4238    69\n",
      "4239    13\n",
      "4240     7\n",
      "Name: Industry, Length: 4241, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Buy Date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Row Labels',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell price',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Buy Date',1,inplace=True)\n",
    "data.drop('Sell date',1,inplace=True)\n",
    "data.drop('Row Labels',1,inplace=True)\n",
    "#data.drop('Symbol',1,inplace=True)\n",
    "data.drop('Return',1,inplace=True)\n",
    "data.drop('Sell price',1,inplace=True)\n",
    "data.drop('Result',axis=1,inplace=True)\n",
    "#data.drop('Nifty Index at buying',axis=1,inplace=True)\n",
    "#data.drop('Nfty index at selling',axis=1,inplace=True)\n",
    "data.drop('Change in Nifty 50',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code'] = pd.factorize(data['Symbol'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4241 entries, 0 to 4240\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Symbol                 4241 non-null   object \n",
      " 1   No of Shares Bought    4241 non-null   int64  \n",
      " 2   Value of purchase      4241 non-null   float64\n",
      " 3   No of shares sold      4241 non-null   int64  \n",
      " 4   Value of sale          4241 non-null   float64\n",
      " 5   No of shares           4241 non-null   int64  \n",
      " 6   Value                  4241 non-null   float64\n",
      " 7   Avg Price              4241 non-null   float64\n",
      " 8   Buy price              4241 non-null   float64\n",
      " 9   Nifty Index at buying  4241 non-null   float64\n",
      " 10  Nfty index at selling  4241 non-null   float64\n",
      " 11  No of shares.1         4241 non-null   int64  \n",
      " 12  Market Cap             4241 non-null   float64\n",
      " 13  %age of Marketcap      4241 non-null   float64\n",
      " 14  Cap                    4241 non-null   int64  \n",
      " 15  Deviation              4241 non-null   float64\n",
      " 16  EPS                    4241 non-null   float64\n",
      " 17  ROE                    4241 non-null   float64\n",
      " 18  COA                    4241 non-null   float64\n",
      " 19  CIA                    4241 non-null   float64\n",
      " 20  CFA                    4241 non-null   float64\n",
      " 21  PBT                    4241 non-null   float64\n",
      " 22  PE                     4241 non-null   float64\n",
      " 23  Industry               4241 non-null   int64  \n",
      " 24  Result5                4241 non-null   object \n",
      " 25  code                   4241 non-null   int64  \n",
      "dtypes: float64(17), int64(7), object(2)\n",
      "memory usage: 861.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2983203324.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Symbol',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Symbol',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score as rs\n",
    "from sklearn.metrics import precision_score as ps\n",
    "from sklearn.metrics import f1_score as fs\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Shares Bought\n"
     ]
    }
   ],
   "source": [
    "print(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No of Shares Bought', 'Value of purchase', 'No of shares sold', 'Value of sale', 'No of shares', 'Value', 'Avg Price', 'Buy price', 'Nifty Index at buying', 'Nfty index at selling', 'No of shares.1', 'Market Cap', '%age of Marketcap', 'Cap', 'Deviation', 'EPS', 'ROE', 'COA', 'CIA', 'CFA', 'PBT', 'PE', 'Industry', 'code']\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for _ in data.columns:\n",
    "    if _ != 'Result5':\n",
    "        features.append(_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data[features]\n",
    "y_score=data['Result5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4241, 24)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4241,)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "lrclassifier= lr()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "lrclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4584882280049566\n",
      "Recall Score :  0.49194388777555115\n",
      "F1 Score :  0.3963574710129075\n",
      "Accuracy :  0.5712603062426383\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result5   pred1\n",
      "3137  PROFIT    LOSS\n",
      "2948  PROFIT    LOSS\n",
      "486   PROFIT    LOSS\n",
      "1050  PROFIT    LOSS\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.array(lrclassifier.predict(X_test))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred1']= lrclassifier.predict(X_test)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_lr_2mon_5.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_lr_2mon_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "dtclassifier = dtc(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "dtclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.6072789354076453\n",
      "Recall Score :  0.6086573146292585\n",
      "F1 Score :  0.6077139286613011\n",
      "Accuracy :  0.6171967020023557\n",
      "\n",
      "\tTable 3\n",
      "\n",
      "     Result5   pred2\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT    LOSS\n",
      "1050  PROFIT    LOSS\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred3 = np.array(dtclassifier.predict(X_test))\n",
    "\n",
    "p_dtc=ps(Y_test, pred3, average='macro',zero_division=1)\n",
    "r_dtc=rs(Y_test, pred3, average='macro',zero_division=1)\n",
    "f1_dtc=fs(Y_test, pred3, average='macro', zero_division=1)\n",
    "ma_dtc=dtclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_dtc)\n",
    "print(\"Recall Score : \",r_dtc)\n",
    "print(\"F1 Score : \", f1_dtc)\n",
    "print(\"Accuracy : \", ma_dtc)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred2']= dtclassifier.predict(X_test)\n",
    "print('\\n\\tTable 3\\n')\n",
    "print(a.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4584882280049566\n",
      "Recall Score :  0.49194388777555115\n",
      "F1 Score :  0.3963574710129075\n",
      "Accuracy :  0.8924302788844621\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result5   pred1\n",
      "3990  PROFIT  PROFIT\n",
      "3991  PROFIT  PROFIT\n",
      "3992    LOSS    LOSS\n",
      "3993  PROFIT  PROFIT\n",
      "3994  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "df_x=X_feature[3990:]\n",
    "df_y=y_score[3990:]\n",
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=dtclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_2mon_test_5.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_2mon_test_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_2mon_5.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_2mon_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - SUPPORT VECTOR MACHINE\n",
    "\n",
    "from sklearn import svm\n",
    "svmclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "svmclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7938751472320377\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3701780415430267\n",
      "Accuracy :  0.5877502944640753\n",
      "\n",
      "\tTable 4\n",
      "\n",
      "     Result5 pred3\n",
      "3137  PROFIT  LOSS\n",
      "2948  PROFIT  LOSS\n",
      "486   PROFIT  LOSS\n",
      "1050  PROFIT  LOSS\n",
      "3401  PROFIT  LOSS\n"
     ]
    }
   ],
   "source": [
    "pred4 = np.array(svmclassifier.predict(X_test))\n",
    "\n",
    "p_svm=ps(Y_test, pred4, average='macro',zero_division=1)\n",
    "r_svm=rs(Y_test, pred4, average='macro',zero_division=1)\n",
    "f1_svm=fs(Y_test, pred4, average='macro', zero_division=1)\n",
    "ma_svm=svmclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_svm)\n",
    "print(\"Recall Score : \",r_svm)\n",
    "print(\"F1 Score : \", f1_svm)\n",
    "print(\"Accuracy : \", ma_svm)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred3']= svmclassifier.predict(X_test)\n",
    "print('\\n\\tTable 4\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_svc_2mon_5.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_svc_2mon_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM BOOST CLASSIFIER\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_estimators=50, learning_rate=0.001, algorithm=SAMME.R, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=10, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "classifier = AdaBoostClassifier(rf,50,0.001,'SAMME.R',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                         min_samples_leaf=2),\n",
       "                   learning_rate=0.001)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.6679167726078481\n",
      "Recall Score :  0.6361294016604637\n",
      "F1 Score :  0.6354084280771132\n",
      "Accuracy :  0.6725559481743227\n",
      "\n",
      "\tTable 5\n",
      "\n",
      "     Result5   pred4\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT    LOSS\n",
      "1050  PROFIT    LOSS\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred5 = np.array(classifier.predict(X_test))\n",
    "\n",
    "p=ps(Y_test, pred5, average='macro',zero_division=1)\n",
    "r=rs(Y_test, pred5, average='macro',zero_division=1)\n",
    "f1=fs(Y_test, pred5, average='macro', zero_division=1)\n",
    "ma=classifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p)\n",
    "print(\"Recall Score : \",r)\n",
    "print(\"F1 Score : \", f1)\n",
    "print(\"Accuracy : \", ma)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred4']= classifier.predict(X_test)\n",
    "print('\\n\\tTable 5\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4584882280049566\n",
      "Recall Score :  0.49194388777555115\n",
      "F1 Score :  0.3963574710129075\n",
      "Accuracy :  0.8725099601593626\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result5   pred1\n",
      "3990  PROFIT  PROFIT\n",
      "3991  PROFIT  PROFIT\n",
      "3992    LOSS    LOSS\n",
      "3993  PROFIT  PROFIT\n",
      "3994  PROFIT    LOSS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred2_test = np.array(classifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=classifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= classifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadaboost_2mon_test_5.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadaboost_2mon_test_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadboost_2mon_5.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadboost_2mon_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.88"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5310715030227225\n",
      "Recall Score :  0.5256026338391068\n",
      "F1 Score :  0.5171509554610069\n",
      "Accuracy :  0.5641931684334511\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result5   pred6\n",
      "3137  PROFIT    LOSS\n",
      "2948  PROFIT    LOSS\n",
      "486   PROFIT  PROFIT\n",
      "1050  PROFIT    LOSS\n",
      "3401  PROFIT    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred6 = np.array(knn.predict(X_test))\n",
    "\n",
    "p_knn=ps(Y_test, pred6, average='macro',zero_division=1)\n",
    "r_knn=rs(Y_test, pred6, average='macro',zero_division=1)\n",
    "f1_knn=fs(Y_test, pred6, average='macro', zero_division=1)\n",
    "ma_knn=knn.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_knn)\n",
    "print(\"Recall Score : \",r_knn)\n",
    "print(\"F1 Score : \", f1_knn)\n",
    "print(\"Accuracy : \", ma_knn)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred6']= knn.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_knn_2mon_5.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_knn_2mon_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.51"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7061248527679623\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.29190992493744783\n",
      "Accuracy :  0.4122497055359246\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result5   pred7\n",
      "3137  PROFIT  PROFIT\n",
      "2948  PROFIT  PROFIT\n",
      "486   PROFIT  PROFIT\n",
      "1050  PROFIT  PROFIT\n",
      "3401  PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred7 = np.array(perceptron.predict(X_test))\n",
    "\n",
    "p_percep=ps(Y_test, pred7, average='macro',zero_division=1)\n",
    "r_percep=rs(Y_test, pred7, average='macro',zero_division=1)\n",
    "f1_percep=fs(Y_test, pred7, average='macro', zero_division=1)\n",
    "ma_percep=perceptron.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_percep)\n",
    "print(\"Recall Score : \",r_percep)\n",
    "print(\"F1 Score : \", f1_percep)\n",
    "print(\"Accuracy : \", ma_percep)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred7']= perceptron.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_percep_2mon_5.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_percep_2mon_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.05"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4719846022241232\n",
      "Recall Score :  0.4981248210707128\n",
      "F1 Score :  0.3810526055653492\n",
      "Accuracy :  0.5830388692579506\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result5 pred8\n",
      "3137  PROFIT  LOSS\n",
      "2948  PROFIT  LOSS\n",
      "486   PROFIT  LOSS\n",
      "1050  PROFIT  LOSS\n",
      "3401  PROFIT  LOSS\n"
     ]
    }
   ],
   "source": [
    "pred8 = np.array(sgd.predict(X_test))\n",
    "\n",
    "p_sgd=ps(Y_test, pred8, average='macro',zero_division=1)\n",
    "r_sgd=rs(Y_test, pred8, average='macro',zero_division=1)\n",
    "f1_sgd=fs(Y_test, pred8, average='macro', zero_division=1)\n",
    "ma_sgd=sgd.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_sgd)\n",
    "print(\"Recall Score : \",r_sgd)\n",
    "print(\"F1 Score : \", f1_sgd)\n",
    "print(\"Accuracy : \", ma_sgd)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred8']= sgd.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end here\n",
    "\n",
    "# 6 months 10% result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            2\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result10                 0\n",
      "dtype: int64\n",
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result10                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Arnab Karmakar/Downloads/6 months.csv\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(how='any',axis=0) \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4069 entries, 0 to 4070\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Row Labels             4069 non-null   object \n",
      " 1   Symbol                 4069 non-null   object \n",
      " 2   No of Shares Bought    4069 non-null   int64  \n",
      " 3   Value of purchase      4069 non-null   float64\n",
      " 4   No of shares sold      4069 non-null   int64  \n",
      " 5   Value of sale          4069 non-null   float64\n",
      " 6   No of shares           4069 non-null   int64  \n",
      " 7   Value                  4069 non-null   float64\n",
      " 8   Avg Price              4069 non-null   float64\n",
      " 9   Buy Date               4069 non-null   object \n",
      " 10  Sell date              4069 non-null   object \n",
      " 11  Buy price              4069 non-null   float64\n",
      " 12  Sell price             4069 non-null   float64\n",
      " 13  Nifty Index at buying  4069 non-null   float64\n",
      " 14  Nfty index at selling  4069 non-null   float64\n",
      " 15  Change in Nifty 50     4069 non-null   object \n",
      " 16  Return                 4069 non-null   float64\n",
      " 17  No of shares.1         4069 non-null   int64  \n",
      " 18  Market Cap             4069 non-null   float64\n",
      " 19  %age of Marketcap      4069 non-null   float64\n",
      " 20  Cap                    4069 non-null   object \n",
      " 21  Deviation              4069 non-null   float64\n",
      " 22  EPS                    4069 non-null   float64\n",
      " 23  ROE                    4069 non-null   float64\n",
      " 24  COA                    4069 non-null   float64\n",
      " 25  CIA                    4069 non-null   float64\n",
      " 26  CFA                    4069 non-null   float64\n",
      " 27  PBT                    4069 non-null   float64\n",
      " 28  PE                     4069 non-null   float64\n",
      " 29  Industry               4069 non-null   object \n",
      " 30  Result                 4069 non-null   object \n",
      " 31  Result10               4069 non-null   object \n",
      "dtypes: float64(19), int64(4), object(9)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'SmallCap':0,'MidCap':1,'LargeCap':2}\n",
    "data['Cap']=data['Cap'].map(c)\n",
    "i={}\n",
    "count=0\n",
    "for _ in data['Industry']:\n",
    "    if _ not in i:\n",
    "        i[_]=count\n",
    "        count+=1\n",
    "data['Industry']=data['Industry'].map(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4066    2\n",
      "4067    0\n",
      "4068    0\n",
      "4069    0\n",
      "4070    1\n",
      "Name: Cap, Length: 4069, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "        ..\n",
      "4066    36\n",
      "4067     0\n",
      "4068     0\n",
      "4069    74\n",
      "4070    94\n",
      "Name: Industry, Length: 4069, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Buy Date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Row Labels',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell price',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Buy Date',1,inplace=True)\n",
    "data.drop('Sell date',1,inplace=True)\n",
    "data.drop('Row Labels',1,inplace=True)\n",
    "#data.drop('Symbol',1,inplace=True)\n",
    "data.drop('Return',1,inplace=True)\n",
    "data.drop('Sell price',1,inplace=True)\n",
    "data.drop('Result',axis=1,inplace=True)\n",
    "#data.drop('Nifty Index at buying',axis=1,inplace=True)\n",
    "#data.drop('Nfty index at selling',axis=1,inplace=True)\n",
    "data.drop('Change in Nifty 50',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code'] = pd.factorize(data['Symbol'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4069 entries, 0 to 4070\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Symbol                 4069 non-null   object \n",
      " 1   No of Shares Bought    4069 non-null   int64  \n",
      " 2   Value of purchase      4069 non-null   float64\n",
      " 3   No of shares sold      4069 non-null   int64  \n",
      " 4   Value of sale          4069 non-null   float64\n",
      " 5   No of shares           4069 non-null   int64  \n",
      " 6   Value                  4069 non-null   float64\n",
      " 7   Avg Price              4069 non-null   float64\n",
      " 8   Buy price              4069 non-null   float64\n",
      " 9   Nifty Index at buying  4069 non-null   float64\n",
      " 10  Nfty index at selling  4069 non-null   float64\n",
      " 11  No of shares.1         4069 non-null   int64  \n",
      " 12  Market Cap             4069 non-null   float64\n",
      " 13  %age of Marketcap      4069 non-null   float64\n",
      " 14  Cap                    4069 non-null   int64  \n",
      " 15  Deviation              4069 non-null   float64\n",
      " 16  EPS                    4069 non-null   float64\n",
      " 17  ROE                    4069 non-null   float64\n",
      " 18  COA                    4069 non-null   float64\n",
      " 19  CIA                    4069 non-null   float64\n",
      " 20  CFA                    4069 non-null   float64\n",
      " 21  PBT                    4069 non-null   float64\n",
      " 22  PE                     4069 non-null   float64\n",
      " 23  Industry               4069 non-null   int64  \n",
      " 24  Result10               4069 non-null   object \n",
      " 25  code                   4069 non-null   int64  \n",
      "dtypes: float64(17), int64(7), object(2)\n",
      "memory usage: 858.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2983203324.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Symbol',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Symbol',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score as rs\n",
    "from sklearn.metrics import precision_score as ps\n",
    "from sklearn.metrics import f1_score as fs\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Shares Bought\n"
     ]
    }
   ],
   "source": [
    "print(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No of Shares Bought', 'Value of purchase', 'No of shares sold', 'Value of sale', 'No of shares', 'Value', 'Avg Price', 'Buy price', 'Nifty Index at buying', 'Nfty index at selling', 'No of shares.1', 'Market Cap', '%age of Marketcap', 'Cap', 'Deviation', 'EPS', 'ROE', 'COA', 'CIA', 'CFA', 'PBT', 'PE', 'Industry', 'code']\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for _ in data.columns:\n",
    "    if _ != 'Result10':\n",
    "        features.append(_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data[features]\n",
    "y_score=data['Result10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4069, 24)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4069,)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "lrclassifier= lr()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "lrclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4182098765432099\n",
      "Recall Score :  0.4983500199242877\n",
      "F1 Score :  0.3717299963463646\n",
      "Accuracy :  0.5847665847665847\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result10 pred1\n",
      "3889   PROFIT  LOSS\n",
      "2843     LOSS  LOSS\n",
      "1909     LOSS  LOSS\n",
      "2940     LOSS  LOSS\n",
      "2435     LOSS  LOSS\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.array(lrclassifier.predict(X_test))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred1']= lrclassifier.predict(X_test)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_lr_6mon_10.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_lr_6mon_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "dtclassifier = dtc(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "dtclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7021432080569885\n",
      "Recall Score :  0.7049524307631002\n",
      "F1 Score :  0.7031859336856092\n",
      "Accuracy :  0.7100737100737101\n",
      "\n",
      "\tTable 3\n",
      "\n",
      "     Result10   pred2\n",
      "3889   PROFIT    LOSS\n",
      "2843     LOSS    LOSS\n",
      "1909     LOSS    LOSS\n",
      "2940     LOSS  PROFIT\n",
      "2435     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred3 = np.array(dtclassifier.predict(X_test))\n",
    "\n",
    "p_dtc=ps(Y_test, pred3, average='macro',zero_division=1)\n",
    "r_dtc=rs(Y_test, pred3, average='macro',zero_division=1)\n",
    "f1_dtc=fs(Y_test, pred3, average='macro', zero_division=1)\n",
    "ma_dtc=dtclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_dtc)\n",
    "print(\"Recall Score : \",r_dtc)\n",
    "print(\"F1 Score : \", f1_dtc)\n",
    "print(\"Accuracy : \", ma_dtc)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred2']= dtclassifier.predict(X_test)\n",
    "print('\\n\\tTable 3\\n')\n",
    "print(a.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4182098765432099\n",
      "Recall Score :  0.4983500199242877\n",
      "F1 Score :  0.3717299963463646\n",
      "Accuracy :  0.908745247148289\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result10   pred1\n",
      "3808   PROFIT  PROFIT\n",
      "3809   PROFIT  PROFIT\n",
      "3810     LOSS    LOSS\n",
      "3811     LOSS    LOSS\n",
      "3812   PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "df_x=X_feature[3806:]\n",
    "df_y=y_score[3806:]\n",
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=dtclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_6mon_test_10.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_6mon_test_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_6mon_10.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_6mon_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - SUPPORT VECTOR MACHINE\n",
    "\n",
    "from sklearn import svm\n",
    "svmclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "svmclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7936117936117937\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.369969040247678\n",
      "Accuracy :  0.5872235872235873\n",
      "\n",
      "\tTable 4\n",
      "\n",
      "     Result10 pred3\n",
      "3889   PROFIT  LOSS\n",
      "2843     LOSS  LOSS\n",
      "1909     LOSS  LOSS\n",
      "2940     LOSS  LOSS\n",
      "2435     LOSS  LOSS\n"
     ]
    }
   ],
   "source": [
    "pred4 = np.array(svmclassifier.predict(X_test))\n",
    "\n",
    "p_svm=ps(Y_test, pred4, average='macro',zero_division=1)\n",
    "r_svm=rs(Y_test, pred4, average='macro',zero_division=1)\n",
    "f1_svm=fs(Y_test, pred4, average='macro', zero_division=1)\n",
    "ma_svm=svmclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_svm)\n",
    "print(\"Recall Score : \",r_svm)\n",
    "print(\"F1 Score : \", f1_svm)\n",
    "print(\"Accuracy : \", ma_svm)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred3']= svmclassifier.predict(X_test)\n",
    "print('\\n\\tTable 4\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_svc_6mon_10.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_svc_6mon_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM BOOST CLASSIFIER\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_estimators=50, learning_rate=0.001, algorithm=SAMME.R, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=10, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "classifier = AdaBoostClassifier(rf,50,0.001,'SAMME.R',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                         min_samples_leaf=2),\n",
       "                   learning_rate=0.001)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7629310344827587\n",
      "Recall Score :  0.7495330245068739\n",
      "F1 Score :  0.7537261146496814\n",
      "Accuracy :  0.7665847665847666\n",
      "\n",
      "\tTable 5\n",
      "\n",
      "     Result10   pred4\n",
      "3889   PROFIT  PROFIT\n",
      "2843     LOSS    LOSS\n",
      "1909     LOSS    LOSS\n",
      "2940     LOSS    LOSS\n",
      "2435     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred5 = np.array(classifier.predict(X_test))\n",
    "\n",
    "p=ps(Y_test, pred5, average='macro',zero_division=1)\n",
    "r=rs(Y_test, pred5, average='macro',zero_division=1)\n",
    "f1=fs(Y_test, pred5, average='macro', zero_division=1)\n",
    "ma=classifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p)\n",
    "print(\"Recall Score : \",r)\n",
    "print(\"F1 Score : \", f1)\n",
    "print(\"Accuracy : \", ma)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred4']= classifier.predict(X_test)\n",
    "print('\\n\\tTable 5\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4182098765432099\n",
      "Recall Score :  0.4983500199242877\n",
      "F1 Score :  0.3717299963463646\n",
      "Accuracy :  0.908745247148289\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result10   pred1\n",
      "3808   PROFIT  PROFIT\n",
      "3809   PROFIT  PROFIT\n",
      "3810     LOSS    LOSS\n",
      "3811     LOSS  PROFIT\n",
      "3812   PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred2_test = np.array(classifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=classifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= classifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadaboost_6mon_test_10.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadaboost_6mon_test_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadboost_6mon_10.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadboost_6mon_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.9"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5346422496957963\n",
      "Recall Score :  0.5320843295477187\n",
      "F1 Score :  0.5303305233889697\n",
      "Accuracy :  0.558968058968059\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result10   pred6\n",
      "3889   PROFIT  PROFIT\n",
      "2843     LOSS  PROFIT\n",
      "1909     LOSS  PROFIT\n",
      "2940     LOSS    LOSS\n",
      "2435     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred6 = np.array(knn.predict(X_test))\n",
    "\n",
    "p_knn=ps(Y_test, pred6, average='macro',zero_division=1)\n",
    "r_knn=rs(Y_test, pred6, average='macro',zero_division=1)\n",
    "f1_knn=fs(Y_test, pred6, average='macro', zero_division=1)\n",
    "ma_knn=knn.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_knn)\n",
    "print(\"Recall Score : \",r_knn)\n",
    "print(\"F1 Score : \", f1_knn)\n",
    "print(\"Accuracy : \", ma_knn)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred6']= knn.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_knn_6mon_10.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_knn_6mon_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.7"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.49841835566242987\n",
      "Recall Score :  0.498623978880255\n",
      "F1 Score :  0.49189515943571654\n",
      "Accuracy :  0.5331695331695332\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result10   pred7\n",
      "3889   PROFIT    LOSS\n",
      "2843     LOSS  PROFIT\n",
      "1909     LOSS    LOSS\n",
      "2940     LOSS    LOSS\n",
      "2435     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred7 = np.array(perceptron.predict(X_test))\n",
    "\n",
    "p_percep=ps(Y_test, pred7, average='macro',zero_division=1)\n",
    "r_percep=rs(Y_test, pred7, average='macro',zero_division=1)\n",
    "f1_percep=fs(Y_test, pred7, average='macro', zero_division=1)\n",
    "ma_percep=perceptron.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_percep)\n",
    "print(\"Recall Score : \",r_percep)\n",
    "print(\"F1 Score : \", f1_percep)\n",
    "print(\"Accuracy : \", ma_percep)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred7']= perceptron.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_percep_6mon_10.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_percep_6mon_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.66"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7063882063882063\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.2921739130434783\n",
      "Accuracy :  0.41277641277641275\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result10   pred8\n",
      "3889   PROFIT  PROFIT\n",
      "2843     LOSS  PROFIT\n",
      "1909     LOSS  PROFIT\n",
      "2940     LOSS  PROFIT\n",
      "2435     LOSS  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred8 = np.array(sgd.predict(X_test))\n",
    "\n",
    "p_sgd=ps(Y_test, pred8, average='macro',zero_division=1)\n",
    "r_sgd=rs(Y_test, pred8, average='macro',zero_division=1)\n",
    "f1_sgd=fs(Y_test, pred8, average='macro', zero_division=1)\n",
    "ma_sgd=sgd.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_sgd)\n",
    "print(\"Recall Score : \",r_sgd)\n",
    "print(\"F1 Score : \", f1_sgd)\n",
    "print(\"Accuracy : \", ma_sgd)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred8']= sgd.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 month 13%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            2\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result13                 0\n",
      "dtype: int64\n",
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result13                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Arnab Karmakar/Downloads/9 months.csv\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(how='any',axis=0) \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3930 entries, 0 to 3931\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Row Labels             3930 non-null   object \n",
      " 1   Symbol                 3930 non-null   object \n",
      " 2   No of Shares Bought    3930 non-null   int64  \n",
      " 3   Value of purchase      3930 non-null   float64\n",
      " 4   No of shares sold      3930 non-null   int64  \n",
      " 5   Value of sale          3930 non-null   float64\n",
      " 6   No of shares           3930 non-null   int64  \n",
      " 7   Value                  3930 non-null   float64\n",
      " 8   Avg Price              3930 non-null   float64\n",
      " 9   Buy Date               3930 non-null   object \n",
      " 10  Sell date              3930 non-null   object \n",
      " 11  Buy price              3930 non-null   float64\n",
      " 12  Sell price             3930 non-null   float64\n",
      " 13  Nifty Index at buying  3930 non-null   float64\n",
      " 14  Nfty index at selling  3930 non-null   float64\n",
      " 15  Change in Nifty 50     3930 non-null   object \n",
      " 16  Return                 3930 non-null   float64\n",
      " 17  No of shares.1         3930 non-null   int64  \n",
      " 18  Market Cap             3930 non-null   float64\n",
      " 19  %age of Marketcap      3930 non-null   float64\n",
      " 20  Cap                    3930 non-null   object \n",
      " 21  Deviation              3930 non-null   float64\n",
      " 22  EPS                    3930 non-null   float64\n",
      " 23  ROE                    3930 non-null   float64\n",
      " 24  COA                    3930 non-null   float64\n",
      " 25  CIA                    3930 non-null   float64\n",
      " 26  CFA                    3930 non-null   float64\n",
      " 27  PBT                    3930 non-null   float64\n",
      " 28  PE                     3930 non-null   float64\n",
      " 29  Industry               3930 non-null   object \n",
      " 30  Result                 3930 non-null   object \n",
      " 31  Result13               3930 non-null   object \n",
      "dtypes: float64(19), int64(4), object(9)\n",
      "memory usage: 1013.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'SmallCap':0,'MidCap':1,'LargeCap':2}\n",
    "data['Cap']=data['Cap'].map(c)\n",
    "i={}\n",
    "count=0\n",
    "for _ in data['Industry']:\n",
    "    if _ not in i:\n",
    "        i[_]=count\n",
    "        count+=1\n",
    "data['Industry']=data['Industry'].map(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3927    0\n",
      "3928    0\n",
      "3929    0\n",
      "3930    1\n",
      "3931    0\n",
      "Name: Cap, Length: 3930, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "        ..\n",
      "3927    13\n",
      "3928     0\n",
      "3929    22\n",
      "3930    94\n",
      "3931     8\n",
      "Name: Industry, Length: 3930, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Buy Date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Row Labels',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell price',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Buy Date',1,inplace=True)\n",
    "data.drop('Sell date',1,inplace=True)\n",
    "data.drop('Row Labels',1,inplace=True)\n",
    "#data.drop('Symbol',1,inplace=True)\n",
    "data.drop('Return',1,inplace=True)\n",
    "data.drop('Sell price',1,inplace=True)\n",
    "data.drop('Result',axis=1,inplace=True)\n",
    "#data.drop('Nifty Index at buying',axis=1,inplace=True)\n",
    "#data.drop('Nfty index at selling',axis=1,inplace=True)\n",
    "data.drop('Change in Nifty 50',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code'] = pd.factorize(data['Symbol'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3930 entries, 0 to 3931\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Symbol                 3930 non-null   object \n",
      " 1   No of Shares Bought    3930 non-null   int64  \n",
      " 2   Value of purchase      3930 non-null   float64\n",
      " 3   No of shares sold      3930 non-null   int64  \n",
      " 4   Value of sale          3930 non-null   float64\n",
      " 5   No of shares           3930 non-null   int64  \n",
      " 6   Value                  3930 non-null   float64\n",
      " 7   Avg Price              3930 non-null   float64\n",
      " 8   Buy price              3930 non-null   float64\n",
      " 9   Nifty Index at buying  3930 non-null   float64\n",
      " 10  Nfty index at selling  3930 non-null   float64\n",
      " 11  No of shares.1         3930 non-null   int64  \n",
      " 12  Market Cap             3930 non-null   float64\n",
      " 13  %age of Marketcap      3930 non-null   float64\n",
      " 14  Cap                    3930 non-null   int64  \n",
      " 15  Deviation              3930 non-null   float64\n",
      " 16  EPS                    3930 non-null   float64\n",
      " 17  ROE                    3930 non-null   float64\n",
      " 18  COA                    3930 non-null   float64\n",
      " 19  CIA                    3930 non-null   float64\n",
      " 20  CFA                    3930 non-null   float64\n",
      " 21  PBT                    3930 non-null   float64\n",
      " 22  PE                     3930 non-null   float64\n",
      " 23  Industry               3930 non-null   int64  \n",
      " 24  Result13               3930 non-null   object \n",
      " 25  code                   3930 non-null   int64  \n",
      "dtypes: float64(17), int64(7), object(2)\n",
      "memory usage: 829.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2983203324.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Symbol',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Symbol',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score as rs\n",
    "from sklearn.metrics import precision_score as ps\n",
    "from sklearn.metrics import f1_score as fs\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Shares Bought\n"
     ]
    }
   ],
   "source": [
    "print(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No of Shares Bought', 'Value of purchase', 'No of shares sold', 'Value of sale', 'No of shares', 'Value', 'Avg Price', 'Buy price', 'Nifty Index at buying', 'Nfty index at selling', 'No of shares.1', 'Market Cap', '%age of Marketcap', 'Cap', 'Deviation', 'EPS', 'ROE', 'COA', 'CIA', 'CFA', 'PBT', 'PE', 'Industry', 'code']\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for _ in data.columns:\n",
    "    if _ != 'Result13':\n",
    "        features.append(_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data[features]\n",
    "y_score=data['Result13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3930, 24)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3930,)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "lrclassifier= lr()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "lrclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4890136424000966\n",
      "Recall Score :  0.49821100917431194\n",
      "F1 Score :  0.38726841126338696\n",
      "Accuracy :  0.5483460559796438\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result13   pred1\n",
      "1527     LOSS    LOSS\n",
      "634    PROFIT    LOSS\n",
      "2278     LOSS  PROFIT\n",
      "794    PROFIT    LOSS\n",
      "2626     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.array(lrclassifier.predict(X_test))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred1']= lrclassifier.predict(X_test)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_lr_9mon_13.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_lr_9mon_13.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "dtclassifier = dtc(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "dtclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7735324545302853\n",
      "Recall Score :  0.7685583224115334\n",
      "F1 Score :  0.7702266815310295\n",
      "Accuracy :  0.7748091603053435\n",
      "\n",
      "\tTable 3\n",
      "\n",
      "     Result13   pred2\n",
      "1527     LOSS    LOSS\n",
      "634    PROFIT  PROFIT\n",
      "2278     LOSS    LOSS\n",
      "794    PROFIT  PROFIT\n",
      "2626     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred3 = np.array(dtclassifier.predict(X_test))\n",
    "\n",
    "p_dtc=ps(Y_test, pred3, average='macro',zero_division=1)\n",
    "r_dtc=rs(Y_test, pred3, average='macro',zero_division=1)\n",
    "f1_dtc=fs(Y_test, pred3, average='macro', zero_division=1)\n",
    "ma_dtc=dtclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_dtc)\n",
    "print(\"Recall Score : \",r_dtc)\n",
    "print(\"F1 Score : \", f1_dtc)\n",
    "print(\"Accuracy : \", ma_dtc)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred2']= dtclassifier.predict(X_test)\n",
    "print('\\n\\tTable 3\\n')\n",
    "print(a.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4890136424000966\n",
      "Recall Score :  0.49821100917431194\n",
      "F1 Score :  0.38726841126338696\n",
      "Accuracy :  0.9386792452830188\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result13   pred1\n",
      "3720     LOSS    LOSS\n",
      "3721     LOSS    LOSS\n",
      "3722   PROFIT  PROFIT\n",
      "3723   PROFIT  PROFIT\n",
      "3724     LOSS  PROFIT\n"
     ]
    }
   ],
   "source": [
    "df_x=X_feature[3718:]\n",
    "df_y=y_score[3718:]\n",
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=dtclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_9mon_test_13.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_9mon_test_13.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_9mon_13.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_9mon_13.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - SUPPORT VECTOR MACHINE\n",
    "\n",
    "from sklearn import svm\n",
    "svmclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "svmclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.48546511627906974\n",
      "Recall Score :  0.4991153342070773\n",
      "F1 Score :  0.3683576092415871\n",
      "Accuracy :  0.5521628498727735\n",
      "\n",
      "\tTable 4\n",
      "\n",
      "     Result13   pred3\n",
      "1527     LOSS  PROFIT\n",
      "634    PROFIT    LOSS\n",
      "2278     LOSS    LOSS\n",
      "794    PROFIT    LOSS\n",
      "2626     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred4 = np.array(svmclassifier.predict(X_test))\n",
    "\n",
    "p_svm=ps(Y_test, pred4, average='macro',zero_division=1)\n",
    "r_svm=rs(Y_test, pred4, average='macro',zero_division=1)\n",
    "f1_svm=fs(Y_test, pred4, average='macro', zero_division=1)\n",
    "ma_svm=svmclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_svm)\n",
    "print(\"Recall Score : \",r_svm)\n",
    "print(\"F1 Score : \", f1_svm)\n",
    "print(\"Accuracy : \", ma_svm)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred3']= svmclassifier.predict(X_test)\n",
    "print('\\n\\tTable 4\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_svc_9mon_13.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_svc_9mon_13.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM BOOST CLASSIFIER\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_estimators=50, learning_rate=0.001, algorithm=SAMME.R, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=10, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "classifier = AdaBoostClassifier(rf,50,0.001,'SAMME.R',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                         min_samples_leaf=2),\n",
       "                   learning_rate=0.001)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.8077093994074872\n",
      "Recall Score :  0.7994823066841416\n",
      "F1 Score :  0.8020006761728615\n",
      "Accuracy :  0.806615776081425\n",
      "\n",
      "\tTable 5\n",
      "\n",
      "     Result13   pred4\n",
      "1527     LOSS    LOSS\n",
      "634    PROFIT  PROFIT\n",
      "2278     LOSS    LOSS\n",
      "794    PROFIT  PROFIT\n",
      "2626     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred5 = np.array(classifier.predict(X_test))\n",
    "\n",
    "p=ps(Y_test, pred5, average='macro',zero_division=1)\n",
    "r=rs(Y_test, pred5, average='macro',zero_division=1)\n",
    "f1=fs(Y_test, pred5, average='macro', zero_division=1)\n",
    "ma=classifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p)\n",
    "print(\"Recall Score : \",r)\n",
    "print(\"F1 Score : \", f1)\n",
    "print(\"Accuracy : \", ma)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred4']= classifier.predict(X_test)\n",
    "print('\\n\\tTable 5\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.4890136424000966\n",
      "Recall Score :  0.49821100917431194\n",
      "F1 Score :  0.38726841126338696\n",
      "Accuracy :  0.8962264150943396\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result13   pred1\n",
      "3720     LOSS    LOSS\n",
      "3721     LOSS    LOSS\n",
      "3722   PROFIT  PROFIT\n",
      "3723   PROFIT  PROFIT\n",
      "3724     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred2_test = np.array(classifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=classifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= classifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadaboost_9mon_test_13.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadaboost_9mon_test_13.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadboost_9mon-13.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadboost_9mon_13.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.95"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5431826288567861\n",
      "Recall Score :  0.5380799475753604\n",
      "F1 Score :  0.5315820118505326\n",
      "Accuracy :  0.5572519083969466\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result13   pred6\n",
      "1527     LOSS    LOSS\n",
      "634    PROFIT    LOSS\n",
      "2278     LOSS    LOSS\n",
      "794    PROFIT  PROFIT\n",
      "2626     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred6 = np.array(knn.predict(X_test))\n",
    "\n",
    "p_knn=ps(Y_test, pred6, average='macro',zero_division=1)\n",
    "r_knn=rs(Y_test, pred6, average='macro',zero_division=1)\n",
    "f1_knn=fs(Y_test, pred6, average='macro', zero_division=1)\n",
    "ma_knn=knn.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_knn)\n",
    "print(\"Recall Score : \",r_knn)\n",
    "print(\"F1 Score : \", f1_knn)\n",
    "print(\"Accuracy : \", ma_knn)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred6']= knn.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_knn_9mon_13.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_knn_9mon_13.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.86"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5561941251596424\n",
      "Recall Score :  0.50086500655308\n",
      "F1 Score :  0.312587582707228\n",
      "Accuracy :  0.44656488549618323\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result13   pred7\n",
      "1527     LOSS  PROFIT\n",
      "634    PROFIT  PROFIT\n",
      "2278     LOSS  PROFIT\n",
      "794    PROFIT  PROFIT\n",
      "2626     LOSS  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred7 = np.array(perceptron.predict(X_test))\n",
    "\n",
    "p_percep=ps(Y_test, pred7, average='macro',zero_division=1)\n",
    "r_percep=rs(Y_test, pred7, average='macro',zero_division=1)\n",
    "f1_percep=fs(Y_test, pred7, average='macro', zero_division=1)\n",
    "ma_percep=perceptron.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_percep)\n",
    "print(\"Recall Score : \",r_percep)\n",
    "print(\"F1 Score : \", f1_percep)\n",
    "print(\"Accuracy : \", ma_percep)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred7']= perceptron.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_percep_9mon_13.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_percep_9mon_13.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.27"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.77735368956743\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3567921440261866\n",
      "Accuracy :  0.55470737913486\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result13 pred8\n",
      "1527     LOSS  LOSS\n",
      "634    PROFIT  LOSS\n",
      "2278     LOSS  LOSS\n",
      "794    PROFIT  LOSS\n",
      "2626     LOSS  LOSS\n"
     ]
    }
   ],
   "source": [
    "pred8 = np.array(sgd.predict(X_test))\n",
    "\n",
    "p_sgd=ps(Y_test, pred8, average='macro',zero_division=1)\n",
    "r_sgd=rs(Y_test, pred8, average='macro',zero_division=1)\n",
    "f1_sgd=fs(Y_test, pred8, average='macro', zero_division=1)\n",
    "ma_sgd=sgd.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_sgd)\n",
    "print(\"Recall Score : \",r_sgd)\n",
    "print(\"F1 Score : \", f1_sgd)\n",
    "print(\"Accuracy : \", ma_sgd)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred8']= sgd.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end here\n",
    "\n",
    "#12 months 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            2\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result15                 0\n",
      "dtype: int64\n",
      "Row Labels               0\n",
      "Symbol                   0\n",
      "No of Shares Bought      0\n",
      "Value of purchase        0\n",
      "No of shares sold        0\n",
      "Value of sale            0\n",
      "No of shares             0\n",
      "Value                    0\n",
      "Avg Price                0\n",
      "Buy Date                 0\n",
      "Sell date                0\n",
      "Buy price                0\n",
      "Sell price               0\n",
      "Nifty Index at buying    0\n",
      "Nfty index at selling    0\n",
      "Change in Nifty 50       0\n",
      "Return                   0\n",
      "No of shares.1           0\n",
      "Market Cap               0\n",
      "%age of Marketcap        0\n",
      "Cap                      0\n",
      "Deviation                0\n",
      "EPS                      0\n",
      "ROE                      0\n",
      "COA                      0\n",
      "CIA                      0\n",
      "CFA                      0\n",
      "PBT                      0\n",
      "PE                       0\n",
      "Industry                 0\n",
      "Result                   0\n",
      "Result15                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Arnab Karmakar/Downloads/12_months.csv\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(how='any',axis=0) \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3800 entries, 0 to 3801\n",
      "Data columns (total 32 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Row Labels             3800 non-null   object \n",
      " 1   Symbol                 3800 non-null   object \n",
      " 2   No of Shares Bought    3800 non-null   int64  \n",
      " 3   Value of purchase      3800 non-null   float64\n",
      " 4   No of shares sold      3800 non-null   int64  \n",
      " 5   Value of sale          3800 non-null   float64\n",
      " 6   No of shares           3800 non-null   int64  \n",
      " 7   Value                  3800 non-null   float64\n",
      " 8   Avg Price              3800 non-null   float64\n",
      " 9   Buy Date               3800 non-null   object \n",
      " 10  Sell date              3800 non-null   object \n",
      " 11  Buy price              3800 non-null   float64\n",
      " 12  Sell price             3800 non-null   float64\n",
      " 13  Nifty Index at buying  3800 non-null   float64\n",
      " 14  Nfty index at selling  3800 non-null   float64\n",
      " 15  Change in Nifty 50     3800 non-null   object \n",
      " 16  Return                 3800 non-null   float64\n",
      " 17  No of shares.1         3800 non-null   int64  \n",
      " 18  Market Cap             3800 non-null   float64\n",
      " 19  %age of Marketcap      3800 non-null   float64\n",
      " 20  Cap                    3800 non-null   object \n",
      " 21  Deviation              3800 non-null   float64\n",
      " 22  EPS                    3800 non-null   float64\n",
      " 23  ROE                    3800 non-null   float64\n",
      " 24  COA                    3800 non-null   float64\n",
      " 25  CIA                    3800 non-null   float64\n",
      " 26  CFA                    3800 non-null   float64\n",
      " 27  PBT                    3800 non-null   float64\n",
      " 28  PE                     3800 non-null   float64\n",
      " 29  Industry               3800 non-null   object \n",
      " 30  Result                 3800 non-null   object \n",
      " 31  Result15               3800 non-null   object \n",
      "dtypes: float64(19), int64(4), object(9)\n",
      "memory usage: 979.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'SmallCap':0,'MidCap':1,'LargeCap':2}\n",
    "data['Cap']=data['Cap'].map(c)\n",
    "i={}\n",
    "count=0\n",
    "for _ in data['Industry']:\n",
    "    if _ not in i:\n",
    "        i[_]=count\n",
    "        count+=1\n",
    "data['Industry']=data['Industry'].map(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3797    0\n",
      "3798    0\n",
      "3799    0\n",
      "3800    0\n",
      "3801    0\n",
      "Name: Cap, Length: 3800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "        ..\n",
      "3797    36\n",
      "3798    66\n",
      "3799    13\n",
      "3800    13\n",
      "3801    14\n",
      "Name: Industry, Length: 3800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Buy Date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Row Labels',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2873873275.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell price',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Buy Date',1,inplace=True)\n",
    "data.drop('Sell date',1,inplace=True)\n",
    "data.drop('Row Labels',1,inplace=True)\n",
    "#data.drop('Symbol',1,inplace=True)\n",
    "data.drop('Return',1,inplace=True)\n",
    "data.drop('Sell price',1,inplace=True)\n",
    "data.drop('Result',axis=1,inplace=True)\n",
    "#data.drop('Nifty Index at buying',axis=1,inplace=True)\n",
    "#data.drop('Nfty index at selling',axis=1,inplace=True)\n",
    "data.drop('Change in Nifty 50',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code'] = pd.factorize(data['Symbol'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3800 entries, 0 to 3801\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Symbol                 3800 non-null   object \n",
      " 1   No of Shares Bought    3800 non-null   int64  \n",
      " 2   Value of purchase      3800 non-null   float64\n",
      " 3   No of shares sold      3800 non-null   int64  \n",
      " 4   Value of sale          3800 non-null   float64\n",
      " 5   No of shares           3800 non-null   int64  \n",
      " 6   Value                  3800 non-null   float64\n",
      " 7   Avg Price              3800 non-null   float64\n",
      " 8   Buy price              3800 non-null   float64\n",
      " 9   Nifty Index at buying  3800 non-null   float64\n",
      " 10  Nfty index at selling  3800 non-null   float64\n",
      " 11  No of shares.1         3800 non-null   int64  \n",
      " 12  Market Cap             3800 non-null   float64\n",
      " 13  %age of Marketcap      3800 non-null   float64\n",
      " 14  Cap                    3800 non-null   int64  \n",
      " 15  Deviation              3800 non-null   float64\n",
      " 16  EPS                    3800 non-null   float64\n",
      " 17  ROE                    3800 non-null   float64\n",
      " 18  COA                    3800 non-null   float64\n",
      " 19  CIA                    3800 non-null   float64\n",
      " 20  CFA                    3800 non-null   float64\n",
      " 21  PBT                    3800 non-null   float64\n",
      " 22  PE                     3800 non-null   float64\n",
      " 23  Industry               3800 non-null   int64  \n",
      " 24  Result15               3800 non-null   object \n",
      " 25  code                   3800 non-null   int64  \n",
      "dtypes: float64(17), int64(7), object(2)\n",
      "memory usage: 801.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2983203324.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Symbol',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Symbol',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score as rs\n",
    "from sklearn.metrics import precision_score as ps\n",
    "from sklearn.metrics import f1_score as fs\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Shares Bought\n"
     ]
    }
   ],
   "source": [
    "print(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No of Shares Bought', 'Value of purchase', 'No of shares sold', 'Value of sale', 'No of shares', 'Value', 'Avg Price', 'Buy price', 'Nifty Index at buying', 'Nfty index at selling', 'No of shares.1', 'Market Cap', '%age of Marketcap', 'Cap', 'Deviation', 'EPS', 'ROE', 'COA', 'CIA', 'CFA', 'PBT', 'PE', 'Industry', 'code']\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for _ in data.columns:\n",
    "    if _ != 'Result15':\n",
    "        features.append(_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data[features]\n",
    "y_score=data['Result15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800, 24)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800,)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "lrclassifier= lr()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "lrclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5100400489487151\n",
      "Recall Score :  0.5101010101010102\n",
      "F1 Score :  0.5098961928066983\n",
      "Accuracy :  0.5131578947368421\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result15   pred1\n",
      "3179   PROFIT  PROFIT\n",
      "2132     LOSS  PROFIT\n",
      "911    PROFIT  PROFIT\n",
      "1012     LOSS  PROFIT\n",
      "1023     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.array(lrclassifier.predict(X_test))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred1']= lrclassifier.predict(X_test)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_lr_12mon_15.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_lr_12mon_15.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "dtclassifier = dtc(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "dtclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7581881533101045\n",
      "Recall Score :  0.759170653907496\n",
      "F1 Score :  0.7585937281840776\n",
      "Accuracy :  0.7605263157894737\n",
      "\n",
      "\tTable 3\n",
      "\n",
      "     Result15   pred2\n",
      "3179   PROFIT  PROFIT\n",
      "2132     LOSS    LOSS\n",
      "911    PROFIT    LOSS\n",
      "1012     LOSS  PROFIT\n",
      "1023     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred3 = np.array(dtclassifier.predict(X_test))\n",
    "\n",
    "p_dtc=ps(Y_test, pred3, average='macro',zero_division=1)\n",
    "r_dtc=rs(Y_test, pred3, average='macro',zero_division=1)\n",
    "f1_dtc=fs(Y_test, pred3, average='macro', zero_division=1)\n",
    "ma_dtc=dtclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_dtc)\n",
    "print(\"Recall Score : \",r_dtc)\n",
    "print(\"F1 Score : \", f1_dtc)\n",
    "print(\"Accuracy : \", ma_dtc)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred2']= dtclassifier.predict(X_test)\n",
    "print('\\n\\tTable 3\\n')\n",
    "print(a.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5100400489487151\n",
      "Recall Score :  0.5101010101010102\n",
      "F1 Score :  0.5098961928066983\n",
      "Accuracy :  0.9315068493150684\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result15   pred1\n",
      "3510   PROFIT  PROFIT\n",
      "3511   PROFIT  PROFIT\n",
      "3512   PROFIT  PROFIT\n",
      "3513   PROFIT  PROFIT\n",
      "3514   PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "df_x=X_feature[3508:]\n",
    "df_y=y_score[3508:]\n",
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=dtclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_12mon_test_15.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_12mon_test_15.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_12mon_15.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_12mon_15.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - SUPPORT VECTOR MACHINE\n",
    "\n",
    "from sklearn import svm\n",
    "svmclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "svmclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.775\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3548387096774194\n",
      "Accuracy :  0.55\n",
      "\n",
      "\tTable 4\n",
      "\n",
      "     Result15 pred3\n",
      "3179   PROFIT  LOSS\n",
      "2132     LOSS  LOSS\n",
      "911    PROFIT  LOSS\n",
      "1012     LOSS  LOSS\n",
      "1023     LOSS  LOSS\n"
     ]
    }
   ],
   "source": [
    "pred4 = np.array(svmclassifier.predict(X_test))\n",
    "\n",
    "p_svm=ps(Y_test, pred4, average='macro',zero_division=1)\n",
    "r_svm=rs(Y_test, pred4, average='macro',zero_division=1)\n",
    "f1_svm=fs(Y_test, pred4, average='macro', zero_division=1)\n",
    "ma_svm=svmclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_svm)\n",
    "print(\"Recall Score : \",r_svm)\n",
    "print(\"F1 Score : \", f1_svm)\n",
    "print(\"Accuracy : \", ma_svm)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred3']= svmclassifier.predict(X_test)\n",
    "print('\\n\\tTable 4\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_svc_12mon_15.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_svc_12mon_15.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM BOOST CLASSIFIER\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_estimators=50, learning_rate=0.001, algorithm=SAMME.R, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=10, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "classifier = AdaBoostClassifier(rf,50,0.001,'SAMME.R',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                         min_samples_leaf=2),\n",
       "                   learning_rate=0.001)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7983458796266678\n",
      "Recall Score :  0.7935938330675173\n",
      "F1 Score :  0.7952092201641778\n",
      "Accuracy :  0.7986842105263158\n",
      "\n",
      "\tTable 5\n",
      "\n",
      "     Result15   pred4\n",
      "3179   PROFIT  PROFIT\n",
      "2132     LOSS    LOSS\n",
      "911    PROFIT    LOSS\n",
      "1012     LOSS    LOSS\n",
      "1023     LOSS    LOSS\n"
     ]
    }
   ],
   "source": [
    "pred5 = np.array(classifier.predict(X_test))\n",
    "\n",
    "p=ps(Y_test, pred5, average='macro',zero_division=1)\n",
    "r=rs(Y_test, pred5, average='macro',zero_division=1)\n",
    "f1=fs(Y_test, pred5, average='macro', zero_division=1)\n",
    "ma=classifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p)\n",
    "print(\"Recall Score : \",r)\n",
    "print(\"F1 Score : \", f1)\n",
    "print(\"Accuracy : \", ma)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred4']= classifier.predict(X_test)\n",
    "print('\\n\\tTable 5\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5100400489487151\n",
      "Recall Score :  0.5101010101010102\n",
      "F1 Score :  0.5098961928066983\n",
      "Accuracy :  0.9178082191780822\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result15   pred1\n",
      "3510   PROFIT  PROFIT\n",
      "3511   PROFIT  PROFIT\n",
      "3512   PROFIT  PROFIT\n",
      "3513   PROFIT  PROFIT\n",
      "3514   PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred2_test = np.array(classifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=classifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= classifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 months test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadaboost_12mon_test_15.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadaboost_12mon_test_15.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadboost_12mon_15.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadboost_12mon_15.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.7"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5433383327084114\n",
      "Recall Score :  0.538809144072302\n",
      "F1 Score :  0.5329828159201809\n",
      "Accuracy :  0.5552631578947368\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result15   pred6\n",
      "3179   PROFIT    LOSS\n",
      "2132     LOSS  PROFIT\n",
      "911    PROFIT    LOSS\n",
      "1012     LOSS    LOSS\n",
      "1023     LOSS  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred6 = np.array(knn.predict(X_test))\n",
    "\n",
    "p_knn=ps(Y_test, pred6, average='macro',zero_division=1)\n",
    "r_knn=rs(Y_test, pred6, average='macro',zero_division=1)\n",
    "f1_knn=fs(Y_test, pred6, average='macro', zero_division=1)\n",
    "ma_knn=knn.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_knn)\n",
    "print(\"Recall Score : \",r_knn)\n",
    "print(\"F1 Score : \", f1_knn)\n",
    "print(\"Accuracy : \", ma_knn)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred6']= knn.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_knn_12mon_15.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_knn_12mon_15.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.16"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.725\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3103448275862069\n",
      "Accuracy :  0.45\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result15   pred7\n",
      "3179   PROFIT  PROFIT\n",
      "2132     LOSS  PROFIT\n",
      "911    PROFIT  PROFIT\n",
      "1012     LOSS  PROFIT\n",
      "1023     LOSS  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred7 = np.array(perceptron.predict(X_test))\n",
    "\n",
    "p_percep=ps(Y_test, pred7, average='macro',zero_division=1)\n",
    "r_percep=rs(Y_test, pred7, average='macro',zero_division=1)\n",
    "f1_percep=fs(Y_test, pred7, average='macro', zero_division=1)\n",
    "ma_percep=perceptron.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_percep)\n",
    "print(\"Recall Score : \",r_percep)\n",
    "print(\"F1 Score : \", f1_percep)\n",
    "print(\"Accuracy : \", ma_percep)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred7']= perceptron.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_percep_12mon_15.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_percep_12mon_15.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.16"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.725\n",
      "Recall Score :  0.5\n",
      "F1 Score :  0.3103448275862069\n",
      "Accuracy :  0.45\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result15   pred8\n",
      "3179   PROFIT  PROFIT\n",
      "2132     LOSS  PROFIT\n",
      "911    PROFIT  PROFIT\n",
      "1012     LOSS  PROFIT\n",
      "1023     LOSS  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred8 = np.array(sgd.predict(X_test))\n",
    "\n",
    "p_sgd=ps(Y_test, pred8, average='macro',zero_division=1)\n",
    "r_sgd=rs(Y_test, pred8, average='macro',zero_division=1)\n",
    "f1_sgd=fs(Y_test, pred8, average='macro', zero_division=1)\n",
    "ma_sgd=sgd.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_sgd)\n",
    "print(\"Recall Score : \",r_sgd)\n",
    "print(\"F1 Score : \", f1_sgd)\n",
    "print(\"Accuracy : \", ma_sgd)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred8']= sgd.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Labels                  0\n",
      "Symbol                      0\n",
      "No of Shares Bought         0\n",
      "Value of purchase           0\n",
      "No of shares sold           0\n",
      "Value of sale               1\n",
      "No of shares                0\n",
      "Value                       0\n",
      "Avg Price                   0\n",
      "Buy Date                    0\n",
      "Sell date                   0\n",
      "Buy price                   0\n",
      "Nifty Index at buying       0\n",
      "No of shares.1              0\n",
      "Market Cap                  0\n",
      "%age of Marketcap           0\n",
      "Cap                         0\n",
      "Deviation                   0\n",
      "EPS                         0\n",
      "ROE                         0\n",
      "COA                         0\n",
      "CIA                         0\n",
      "CFA                         0\n",
      "PBT                         0\n",
      "PE                          0\n",
      "Industry                    0\n",
      "Sell price(2)               0\n",
      "Nfty index at selling(2)    0\n",
      "Change in Nifty 50(2)       0\n",
      "Change in Nifty 50(6)       0\n",
      "Change in Nifty 50(9)       0\n",
      "Change in Nifty 50(12)      0\n",
      "Return(2)                   0\n",
      "Return(6)                   0\n",
      "Return(9)                   0\n",
      "Return(12)                  0\n",
      "Return                      0\n",
      "Change in Nifty 50          0\n",
      "Result15                    0\n",
      "dtype: int64\n",
      "Row Labels                  0\n",
      "Symbol                      0\n",
      "No of Shares Bought         0\n",
      "Value of purchase           0\n",
      "No of shares sold           0\n",
      "Value of sale               0\n",
      "No of shares                0\n",
      "Value                       0\n",
      "Avg Price                   0\n",
      "Buy Date                    0\n",
      "Sell date                   0\n",
      "Buy price                   0\n",
      "Nifty Index at buying       0\n",
      "No of shares.1              0\n",
      "Market Cap                  0\n",
      "%age of Marketcap           0\n",
      "Cap                         0\n",
      "Deviation                   0\n",
      "EPS                         0\n",
      "ROE                         0\n",
      "COA                         0\n",
      "CIA                         0\n",
      "CFA                         0\n",
      "PBT                         0\n",
      "PE                          0\n",
      "Industry                    0\n",
      "Sell price(2)               0\n",
      "Nfty index at selling(2)    0\n",
      "Change in Nifty 50(2)       0\n",
      "Change in Nifty 50(6)       0\n",
      "Change in Nifty 50(9)       0\n",
      "Change in Nifty 50(12)      0\n",
      "Return(2)                   0\n",
      "Return(6)                   0\n",
      "Return(9)                   0\n",
      "Return(12)                  0\n",
      "Return                      0\n",
      "Change in Nifty 50          0\n",
      "Result15                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Arnab Karmakar/Downloads/max.csv\")\n",
    "print(data.isnull().sum())\n",
    "data = data.dropna(how='any',axis=0) \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3082 entries, 0 to 3082\n",
      "Data columns (total 39 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Row Labels                3082 non-null   object \n",
      " 1   Symbol                    3082 non-null   object \n",
      " 2   No of Shares Bought       3082 non-null   int64  \n",
      " 3   Value of purchase         3082 non-null   float64\n",
      " 4   No of shares sold         3082 non-null   int64  \n",
      " 5   Value of sale             3082 non-null   float64\n",
      " 6   No of shares              3082 non-null   int64  \n",
      " 7   Value                     3082 non-null   float64\n",
      " 8   Avg Price                 3082 non-null   float64\n",
      " 9   Buy Date                  3082 non-null   object \n",
      " 10  Sell date                 3082 non-null   object \n",
      " 11  Buy price                 3082 non-null   float64\n",
      " 12  Nifty Index at buying     3082 non-null   float64\n",
      " 13  No of shares.1            3082 non-null   int64  \n",
      " 14  Market Cap                3082 non-null   float64\n",
      " 15  %age of Marketcap         3082 non-null   float64\n",
      " 16  Cap                       3082 non-null   object \n",
      " 17  Deviation                 3082 non-null   float64\n",
      " 18  EPS                       3082 non-null   float64\n",
      " 19  ROE                       3082 non-null   float64\n",
      " 20  COA                       3082 non-null   float64\n",
      " 21  CIA                       3082 non-null   float64\n",
      " 22  CFA                       3082 non-null   float64\n",
      " 23  PBT                       3082 non-null   float64\n",
      " 24  PE                        3082 non-null   float64\n",
      " 25  Industry                  3082 non-null   object \n",
      " 26  Sell price(2)             3082 non-null   float64\n",
      " 27  Nfty index at selling(2)  3082 non-null   object \n",
      " 28  Change in Nifty 50(2)     3082 non-null   object \n",
      " 29  Change in Nifty 50(6)     3082 non-null   object \n",
      " 30  Change in Nifty 50(9)     3082 non-null   object \n",
      " 31  Change in Nifty 50(12)    3082 non-null   object \n",
      " 32  Return(2)                 3082 non-null   object \n",
      " 33  Return(6)                 3082 non-null   object \n",
      " 34  Return(9)                 3082 non-null   object \n",
      " 35  Return(12)                3082 non-null   object \n",
      " 36  Return                    3082 non-null   float64\n",
      " 37  Change in Nifty 50        3082 non-null   float64\n",
      " 38  Result15                  3082 non-null   object \n",
      "dtypes: float64(19), int64(4), object(16)\n",
      "memory usage: 963.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'SmallCap':0,'MidCap':1,'LargeCap':2}\n",
    "data['Cap']=data['Cap'].map(c)\n",
    "i={}\n",
    "count=0\n",
    "for _ in data['Industry']:\n",
    "    if _ not in i:\n",
    "        i[_]=count\n",
    "        count+=1\n",
    "data['Industry']=data['Industry'].map(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3078    1\n",
      "3079    0\n",
      "3080    0\n",
      "3081    0\n",
      "3082    0\n",
      "Name: Cap, Length: 3082, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Cap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        1\n",
      "2        2\n",
      "3        3\n",
      "4        4\n",
      "        ..\n",
      "3078    26\n",
      "3079    14\n",
      "3080    60\n",
      "3081    68\n",
      "3082    12\n",
      "Name: Industry, Length: 3082, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Industry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3503640539.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Buy Date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3503640539.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Sell date',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3503640539.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Row Labels',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3503640539.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3503640539.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return(2)',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3503640539.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return(6)',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3503640539.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return(9)',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3503640539.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Return(12)',1,inplace=True)\n",
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\3503640539.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop(\"Sell price(2)\",1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Buy Date',1,inplace=True)\n",
    "data.drop('Sell date',1,inplace=True)\n",
    "data.drop('Row Labels',1,inplace=True)\n",
    "#data.drop('Symbol',1,inplace=True)\n",
    "data.drop('Return',1,inplace=True)\n",
    "data.drop('Return(2)',1,inplace=True)\n",
    "data.drop('Return(6)',1,inplace=True)\n",
    "data.drop('Return(9)',1,inplace=True)\n",
    "data.drop('Return(12)',1,inplace=True)\n",
    "data.drop(\"Sell price(2)\",1,inplace=True)\n",
    "#data.drop('Result3',axis=1,inplace=True)\n",
    "#data.drop('Nifty Index at buying',axis=1,inplace=True)\n",
    "data.drop(\"Nfty index at selling(2)\",axis=1,inplace=True)\n",
    "data.drop(\"Change in Nifty 50(2)\",axis=1,inplace=True)\n",
    "data.drop(\"Change in Nifty 50(6)\",axis=1,inplace=True)\n",
    "data.drop(\"Change in Nifty 50(9)\",axis=1,inplace=True)\n",
    "data.drop(\"Change in Nifty 50(12)\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['code'] = pd.factorize(data['Symbol'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3082 entries, 0 to 3082\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Symbol                 3082 non-null   object \n",
      " 1   No of Shares Bought    3082 non-null   int64  \n",
      " 2   Value of purchase      3082 non-null   float64\n",
      " 3   No of shares sold      3082 non-null   int64  \n",
      " 4   Value of sale          3082 non-null   float64\n",
      " 5   No of shares           3082 non-null   int64  \n",
      " 6   Value                  3082 non-null   float64\n",
      " 7   Avg Price              3082 non-null   float64\n",
      " 8   Buy price              3082 non-null   float64\n",
      " 9   Nifty Index at buying  3082 non-null   float64\n",
      " 10  No of shares.1         3082 non-null   int64  \n",
      " 11  Market Cap             3082 non-null   float64\n",
      " 12  %age of Marketcap      3082 non-null   float64\n",
      " 13  Cap                    3082 non-null   int64  \n",
      " 14  Deviation              3082 non-null   float64\n",
      " 15  EPS                    3082 non-null   float64\n",
      " 16  ROE                    3082 non-null   float64\n",
      " 17  COA                    3082 non-null   float64\n",
      " 18  CIA                    3082 non-null   float64\n",
      " 19  CFA                    3082 non-null   float64\n",
      " 20  PBT                    3082 non-null   float64\n",
      " 21  PE                     3082 non-null   float64\n",
      " 22  Industry               3082 non-null   int64  \n",
      " 23  Change in Nifty 50     3082 non-null   float64\n",
      " 24  Result15               3082 non-null   object \n",
      " 25  code                   3082 non-null   int64  \n",
      "dtypes: float64(17), int64(7), object(2)\n",
      "memory usage: 650.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\AppData\\Local\\Temp\\ipykernel_16400\\2983203324.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  data.drop('Symbol',1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop('Symbol',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score as rs\n",
    "from sklearn.metrics import precision_score as ps\n",
    "from sklearn.metrics import f1_score as fs\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Shares Bought\n"
     ]
    }
   ],
   "source": [
    "print(data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No of Shares Bought', 'Value of purchase', 'No of shares sold', 'Value of sale', 'No of shares', 'Value', 'Avg Price', 'Buy price', 'Nifty Index at buying', 'No of shares.1', 'Market Cap', '%age of Marketcap', 'Cap', 'Deviation', 'EPS', 'ROE', 'COA', 'CIA', 'CFA', 'PBT', 'PE', 'Industry', 'Change in Nifty 50', 'code']\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "for _ in data.columns:\n",
    "    if _ != 'Result15':\n",
    "        features.append(_)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature=data[features]\n",
    "y_score=data['Result15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3082, 24)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3082,)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=X_feature[2847:]\n",
    "df_y=y_score[2847:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "\n",
    "lrclassifier= lr()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "lrclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5599509803921568\n",
      "Recall Score :  0.506445934265174\n",
      "F1 Score :  0.37695997307228407\n",
      "Accuracy :  0.5332252836304701\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result15   pred1\n",
      "319      LOSS  PROFIT\n",
      "1920     LOSS  PROFIT\n",
      "752      LOSS  PROFIT\n",
      "1218     LOSS  PROFIT\n",
      "706    PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.array(lrclassifier.predict(X_test))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=lrclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred1']= lrclassifier.predict(X_test)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_lr_max.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_lr_max.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE CLASSIFIER\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "dtclassifier = dtc(max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "dtclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7512940231973464\n",
      "Recall Score :  0.7507642358695423\n",
      "F1 Score :  0.7509793214785974\n",
      "Accuracy :  0.7520259319286872\n",
      "\n",
      "\tTable 3\n",
      "\n",
      "     Result15   pred2\n",
      "319      LOSS  PROFIT\n",
      "1920     LOSS    LOSS\n",
      "752      LOSS    LOSS\n",
      "1218     LOSS    LOSS\n",
      "706    PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred3 = np.array(dtclassifier.predict(X_test))\n",
    "\n",
    "p_dtc=ps(Y_test, pred3, average='macro',zero_division=1)\n",
    "r_dtc=rs(Y_test, pred3, average='macro',zero_division=1)\n",
    "f1_dtc=fs(Y_test, pred3, average='macro', zero_division=1)\n",
    "ma_dtc=dtclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_dtc)\n",
    "print(\"Recall Score : \",r_dtc)\n",
    "print(\"F1 Score : \", f1_dtc)\n",
    "print(\"Accuracy : \", ma_dtc)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred2']= dtclassifier.predict(X_test)\n",
    "print('\\n\\tTable 3\\n')\n",
    "print(a.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5599509803921568\n",
      "Recall Score :  0.506445934265174\n",
      "F1 Score :  0.37695997307228407\n",
      "Accuracy :  0.9787234042553191\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result15   pred1\n",
      "2848   PROFIT  PROFIT\n",
      "2849   PROFIT  PROFIT\n",
      "2850   PROFIT  PROFIT\n",
      "2851   PROFIT  PROFIT\n",
      "2852   PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(dtclassifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=dtclassifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= dtclassifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_max_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_max_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_decision_max.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_decision_max.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - SUPPORT VECTOR MACHINE\n",
    "\n",
    "from sklearn import svm\n",
    "svmclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "svmclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7646103896103896\n",
      "Recall Score :  0.5017182130584192\n",
      "F1 Score :  0.34949684437076467\n",
      "Accuracy :  0.5299837925445705\n",
      "\n",
      "\tTable 4\n",
      "\n",
      "     Result15   pred3\n",
      "319      LOSS  PROFIT\n",
      "1920     LOSS  PROFIT\n",
      "752      LOSS  PROFIT\n",
      "1218     LOSS  PROFIT\n",
      "706    PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred4 = np.array(svmclassifier.predict(X_test))\n",
    "\n",
    "p_svm=ps(Y_test, pred4, average='macro',zero_division=1)\n",
    "r_svm=rs(Y_test, pred4, average='macro',zero_division=1)\n",
    "f1_svm=fs(Y_test, pred4, average='macro', zero_division=1)\n",
    "ma_svm=svmclassifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_svm)\n",
    "print(\"Recall Score : \",r_svm)\n",
    "print(\"F1 Score : \", f1_svm)\n",
    "print(\"Accuracy : \", ma_svm)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred3']= svmclassifier.predict(X_test)\n",
    "print('\\n\\tTable 4\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_svc_max.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_svc_max.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM BOOST CLASSIFIER\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab Karmakar\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_estimators=50, learning_rate=0.001, algorithm=SAMME.R, random_state=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=10, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=2, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "classifier = AdaBoostClassifier(rf,50,0.001,'SAMME.R',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=10,\n",
       "                                                         min_samples_leaf=2),\n",
       "                   learning_rate=0.001)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_feature,y_score, test_size= 0.2, random_state= 1)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7903049421661409\n",
      "Recall Score :  0.7910210191217085\n",
      "F1 Score :  0.7892582394484615\n",
      "Accuracy :  0.7893030794165316\n",
      "\n",
      "\tTable 5\n",
      "\n",
      "     Result15   pred4\n",
      "319      LOSS  PROFIT\n",
      "1920     LOSS    LOSS\n",
      "752      LOSS    LOSS\n",
      "1218     LOSS    LOSS\n",
      "706    PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred5 = np.array(classifier.predict(X_test))\n",
    "\n",
    "p=ps(Y_test, pred5, average='macro',zero_division=1)\n",
    "r=rs(Y_test, pred5, average='macro',zero_division=1)\n",
    "f1=fs(Y_test, pred5, average='macro', zero_division=1)\n",
    "ma=classifier.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p)\n",
    "print(\"Recall Score : \",r)\n",
    "print(\"F1 Score : \", f1)\n",
    "print(\"Accuracy : \", ma)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred4']= classifier.predict(X_test)\n",
    "print('\\n\\tTable 5\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5599509803921568\n",
      "Recall Score :  0.506445934265174\n",
      "F1 Score :  0.37695997307228407\n",
      "Accuracy :  0.9617021276595744\n",
      "\n",
      "\tTable 2\n",
      "\n",
      "     Result15   pred1\n",
      "2848   PROFIT  PROFIT\n",
      "2849   PROFIT  PROFIT\n",
      "2850   PROFIT  PROFIT\n",
      "2851   PROFIT  PROFIT\n",
      "2852   PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred2_test = np.array(classifier.predict(df_x))\n",
    "\n",
    "p_lr=ps(Y_test, pred2, average='macro',zero_division=1)\n",
    "r_lr=rs(Y_test, pred2, average='macro',zero_division=1)\n",
    "f1_lr=fs(Y_test, pred2, average='macro', zero_division=1)\n",
    "ma_lr=classifier.score(df_x,df_y)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_lr)\n",
    "print(\"Recall Score : \",r_lr)\n",
    "print(\"F1 Score : \", f1_lr)\n",
    "print(\"Accuracy : \", ma_lr)\n",
    "\n",
    "\n",
    "a1 = pd.DataFrame(df_y)\n",
    "a1['pred1']= classifier.predict(df_x)\n",
    "print('\\n\\tTable 2\\n')\n",
    "print(a1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max test\n",
    "df_x.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadaboost_max_test.xlsx\")\n",
    "a1.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadaboost_max_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_rfadboost_max.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_rfadboost_max.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.76"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.530554712488035\n",
      "Recall Score :  0.527591550186579\n",
      "F1 Score :  0.5197842509742452\n",
      "Accuracy :  0.5364667747163695\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result15   pred6\n",
      "319      LOSS  PROFIT\n",
      "1920     LOSS    LOSS\n",
      "752      LOSS  PROFIT\n",
      "1218     LOSS  PROFIT\n",
      "706    PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred6 = np.array(knn.predict(X_test))\n",
    "\n",
    "p_knn=ps(Y_test, pred6, average='macro',zero_division=1)\n",
    "r_knn=rs(Y_test, pred6, average='macro',zero_division=1)\n",
    "f1_knn=fs(Y_test, pred6, average='macro', zero_division=1)\n",
    "ma_knn=knn.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_knn)\n",
    "print(\"Recall Score : \",r_knn)\n",
    "print(\"F1 Score : \", f1_knn)\n",
    "print(\"Accuracy : \", ma_knn)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred6']= knn.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_knn_max.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_knn_max.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.06"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(X_train, Y_train)\n",
    "Y_pred = perceptron.predict(X_test)\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.5694896851248643\n",
      "Recall Score :  0.5013492716041574\n",
      "F1 Score :  0.3265210163058993\n",
      "Accuracy :  0.473257698541329\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result15 pred7\n",
      "319      LOSS  LOSS\n",
      "1920     LOSS  LOSS\n",
      "752      LOSS  LOSS\n",
      "1218     LOSS  LOSS\n",
      "706    PROFIT  LOSS\n"
     ]
    }
   ],
   "source": [
    "pred7 = np.array(perceptron.predict(X_test))\n",
    "\n",
    "p_percep=ps(Y_test, pred7, average='macro',zero_division=1)\n",
    "r_percep=rs(Y_test, pred7, average='macro',zero_division=1)\n",
    "f1_percep=fs(Y_test, pred7, average='macro', zero_division=1)\n",
    "ma_percep=perceptron.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_percep)\n",
    "print(\"Recall Score : \",r_percep)\n",
    "print(\"F1 Score : \", f1_percep)\n",
    "print(\"Accuracy : \", ma_percep)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred7']= perceptron.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_percep_max.xlsx\")\n",
    "a.to_excel(\"C:/Users/Arnab Karmakar/Downloads/test_data_pred_percep_max.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.27"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation metrics for test dataset ***\n",
      "\n",
      "Precision Score :  0.7646103896103896\n",
      "Recall Score :  0.5017182130584192\n",
      "F1 Score :  0.34949684437076467\n",
      "Accuracy :  0.5299837925445705\n",
      "\n",
      "\tTable\n",
      "\n",
      "     Result15   pred8\n",
      "319      LOSS  PROFIT\n",
      "1920     LOSS  PROFIT\n",
      "752      LOSS  PROFIT\n",
      "1218     LOSS  PROFIT\n",
      "706    PROFIT  PROFIT\n"
     ]
    }
   ],
   "source": [
    "pred8 = np.array(sgd.predict(X_test))\n",
    "\n",
    "p_sgd=ps(Y_test, pred8, average='macro',zero_division=1)\n",
    "r_sgd=rs(Y_test, pred8, average='macro',zero_division=1)\n",
    "f1_sgd=fs(Y_test, pred8, average='macro', zero_division=1)\n",
    "ma_sgd=sgd.score(X_test,Y_test)\n",
    "\n",
    "print('*** Evaluation metrics for test dataset ***\\n')\n",
    "print(\"Precision Score : \",p_sgd)\n",
    "print(\"Recall Score : \",r_sgd)\n",
    "print(\"F1 Score : \", f1_sgd)\n",
    "print(\"Accuracy : \", ma_sgd)\n",
    "\n",
    "\n",
    "a = pd.DataFrame(Y_test)\n",
    "a['pred8']= sgd.predict(X_test)\n",
    "print('\\n\\tTable\\n')\n",
    "print(a.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f97e529747ebd75ab7a7eec8530cad2ed8018c456aefe1ed5a69bb21bdfd2052"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
